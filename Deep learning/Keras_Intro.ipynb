{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Keras_Intro.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "uW4Yv1FWKsUE"
      },
      "source": [
        "# Machine Learning Foundation\n",
        "\n",
        "## Course 5, Part d: Keras Intro LAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjjpNEKxKsUI"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf6OyoYxKsUJ"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## UCI Pima Diabetes Dataset\n",
        "\n",
        "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8t_L8nSKsUJ"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf6xcjM5KsUK"
      },
      "source": [
        "#Setup\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW-T_ogwKsUK"
      },
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqloEV5ZKsUL"
      },
      "source": [
        "## Load in the data set \n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv('/content/sample_data/diabetes.csv', names=names, header=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "2fS_-I45KsUL",
        "outputId": "77cc2d77-72d0-491c-e79a-4e4e7e594baf"
      },
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>5</td>\n",
              "      <td>124</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.220</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>4</td>\n",
              "      <td>109</td>\n",
              "      <td>64</td>\n",
              "      <td>44</td>\n",
              "      <td>99</td>\n",
              "      <td>34.8</td>\n",
              "      <td>0.905</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>86</td>\n",
              "      <td>36</td>\n",
              "      <td>120</td>\n",
              "      <td>45.5</td>\n",
              "      <td>0.127</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>8</td>\n",
              "      <td>196</td>\n",
              "      <td>76</td>\n",
              "      <td>29</td>\n",
              "      <td>280</td>\n",
              "      <td>37.5</td>\n",
              "      <td>0.605</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>8</td>\n",
              "      <td>105</td>\n",
              "      <td>100</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.239</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  ...  age  has_diabetes\n",
              "116               5                     124  ...   38             1\n",
              "198               4                     109  ...   26             1\n",
              "328               2                     102  ...   23             1\n",
              "206               8                     196  ...   57             1\n",
              "387               8                     105  ...   45             1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDTPEx2VKsUL"
      },
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-JwtdLoKsUM"
      },
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO59jXxLKsUM",
        "outputId": "2ee73df7-658f-4ff0-f32d-236193bef938"
      },
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd6kfoBIKsUM"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise 1: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FsilGWNKsUN",
        "outputId": "2278dde9-8c62-427d-a41d-a08e38d76b64"
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-5k0WlIKsUN",
        "outputId": "967eeff6-aa33-49b0-f7e8-abb63ef35a54"
      },
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.781\n",
            "roc-auc is 0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "g_OjmTu8KsUN",
        "outputId": "0e97a38d-dacc-41eb-e7c1-f16b576985c4"
      },
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
        "### END SOLUTION"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUZd7/8fcdCKEIAQRBCE2KyNpogiyrLFbA3n6AjV1ddR9Z6QSQKggKCuIjuliAB11EV1FxCYoIAcRCVyCAlEiTXhIgCWn3748Z2BgTSJnJPeXzuq65mDNz5sxn7gzzne+ZU4y1FhEREQkcEa4DiIiIyG+pOIuIiAQYFWcREZEAo+IsIiISYFScRUREAoyKs4iISIBRcZawZIwpZ4z53BiTZIz5t+s84cQY08MY802O6ZPGmEsK8Lj6xhhrjCnt34TunO81GmNGGmPeK+lcUvJUnMOAMeYXY0yq90NwvzFmhjHmglzztDPGLDLGnPAWrM+NMc1yzVPJGPOKMWaXd1nbvdPV8nleY4x5xhizwRhzyhizxxjzb2PMFf58vQV0H1ADuNBae39xF2aM6WCMyfaOywljzBZjzF9yzWO943DSezle3OctQK4Zxph07/MdNcZ8ZYxp6r3vNx/03nwHcxYGY0yk97bfHRDBu+xMY8zFxclorb3AWrujOMs4n3Ao7BJaVJzDx+3W2guAq4HmwOAzdxhjrgUWAJ8BtYAGwI/A8jMdjTGmDPA18AfgVqAScC1wBLgmn+ecDPQCngGqAk2AT4EuhQ3vhw/VesDP1tpMH2b51TvGlYA+wFvGmEtzzXOVtxhdYK2tXNjnLqLx3lwxwEFgxjnmPQZ0yjHdyXvbbxhjKgD3AknAQz5LGuL05UAKSsU5zFhr9wNf4inSZ4wHZlprJ1trT1hrj1prhwLfAyO98zwC1AXuttYmWGuzrbUHrbWjrbVxuZ/HGNMYeBroZq1dZK09ba1Nsdb+y1r7gneeeGPM4zkek3t1pzXGPG2M2QpsNca8YYx5KdfzfGaM6eu9XssY87Ex5pAxJtEY80xeY2CMGQUMB/6ft6N8zBgTYYwZaozZ6e0UZxpjor3zn+m6HjPG7AIWnWeMrXdMjgJXnmvefPIVJMuj3jUYh40xzxZkudbaFGAWcPk5ZnsXz9/6jEeAmXnMdy9wHHgOePQ8r+dCY8xcY0yyMWYF0DDX/dYY08h7vYsxZq133t3GmJF5LPKvxphfjTH7jDH9cywnwhgzyLtG54gx5kNjTFXv3Uu9/x73/s2v9T7mr8aYTcaYY8aYL40x9by3G2PMJO/4Jxtj1htj8hw37/t4nDFmhXfez848b17vnXP9fc/3GvN47rbGmG+NMceNMT8aYzrkyjXGe/9J41kbdqEx5l/enCuNMfXzW7Y4Zq3VJcQvwC/Ajd7rMcB6YLJ3ujyQBfw5j8f9BdjnvT4b+L9CPOdTwM7zzBMPPJ5jugfwTY5pC3yFp+suB1wH7AaM9/4qQCqebj8CWI2n6JYBLgF2ALfk89wjgfdyTP8V2OZ93AXAHOBd7331vVlmAhWAcnksrwOwx3s9ArgDyAaa53o9jQowdgXJ8pZ3TK4CTgOX5bOsGcAY7/UL8BTnZfmMgcVTuA8Alb3je8B7m8213K/xfKmrAWQCLc/xemYDH3rH7nJgbx5/50Y5xvEK7xhe6X3+u3K99ve9y7oCOMR/39u98HyhjAGigKnA+7keWzrH897pHefLgNLAUOBb7323eN9PlQHjnefic7yP93pfWwXg4zPjmtd7p4B/3/xe48gcy66NZ81VZ+943eSdrp4j1zY8X4aigQTgZ+BG7+udCUx3/fmkSz7/b1wH0KUE/sie4nwSOOH9j/81UNl7X4z3tqZ5PO5WIMN7/SvghUI857PA9+eZJ57zF+eOOaYNsAu4zjv9N2CR93obYFeu5Q/O78OH3xemr4H/yTF9KZDh/RA784F5yTleSwc8xfg4nmKZBfTONY8Fkr3zHAdezWdZBckSk+P+FUDXfJY1A0jzPt9+YC7QMJ8xsEAj4G3gSTxfsN7y3mZzzFfX+1qv9k5/iffLXh7PX8qbvWmO28bm8XfO80sL8AowyXv9zGvPuazxwDve65uAG3Lcd3Ee45azOM8HHssxHQGk4PnJoyOeQtYWiCjA+/iFHNPNgHTva//de6eAf9/8XuPZvxkQi7eo55j3S+DRHLmezXHfy8D8HNO3A+sK+n9al5K9aLV2+LjLWlsRTxFpCpzZiOsYng/avDbquRg47L1+JJ958lPY+fOz+8wV6/lEmQ10897UHfiX93o9oJZ39d5x49nYagiezq4gagE7c0zvxPNhmfPxuzm3X63nd+RKwKt4PuBza2Gtrey95LnavYBZ9ue4noKnA8vPS97nq2mtvcNau/08r2MmntXZ+a3SfhjYZK1d553+F9DdGBOZx7zVvdlzjt3OPOYDwBjTxhiz2PvTRBKeLwi5NzjMvaxa3uv1gE9y/P034fmSlN97oB4wOcf8R/F8AaxtrV0EvAZMAQ4aY940xlTKL3cemSJz5c55f2HfazlfY+789+d6z7fnt//vDuS4nprH9LneN+KQinOYsdYuwdNNveSdPgV8B+S1xfIDeL7lAywEbjGeDYEK4msgxhjT6hzznMKzWv2MmnlFzjX9PnCf97fBNnhWIYLnwywxR+GrbK2taK3tXMC8v+L5sDujLp7VtTk/zAp0Cjdr7Wk8Xc0Vxpi7Cvj8hc3iT8vwfMDXAL7J4/5HgEuMZ8v//cBEPIUor7E+hCd7nRy31T3Hc8/C093XsdZGA//EUzBzyr2sX73XdwOdcr0Hylpr95L332438GSu+ctZa78FsNa+aq1tiacTbgIMOEfu3Jky+O8XW3I9f0H+vvm9xtz5382Vv4L1btMhwU3FOTy9AtxkjLnKOz0IeNR4dnuqaIypYowZg2dr7FHeed7F82HwsTGmqXejlguNMUOMMb/7ULbWbgVeB943nt2MyhhjyhpjuhpjBnlnWwfcY4wp790g6LHzBbfWrsXzofc28KW19szuSCuAE8aYWOPZh7mUMeZyY0zrAo7J+0AfY0wD49nNbCzwgS3C1tzenOl4ViMOL8LDfZqlsLxrKG4H7vBeP8u7IVVDPFvoX+29XI6nqD6Sa1FYa7Pw/KY60vt3bsa5NyCrCBy11qYZY67Bs3Ykt2HeZf0Bz3YRH3hv/yfwfI6NuqobY+703ncIzxqinPtT/xMY7F0OxphoY8z93uutvV18JJ4vkWnex+fnIWNMM2NMeTwbyX3kfe15KcjfN7/XmNN7wO3GmFu87/ey3v9rMefIKUFCxTkMWWsP4VldOdw7/Q2eDWDuAfbhWY3WHGjvLbJnusEbgc14fn9OxlMQqwE/5PNUz/DfVYPHge3A3cDn3vsn4flt7gDwf/x3FfX5zPJmmZXjNWUBt+EpFon8t4Dn3go2P9PwfAFZ6n18GvCPAj72XMusa4y5vQiP83WWQrHWbrTWbszjrkeBz6y16621+89c8Ow2d5v579bROfXEs/p0P561NtPP8dT/AzxnjDmB5/35YR7zLMGzodPXeFbZL/DePhlP173A+/jv8axdwXq2VH8ez+6Bx40xba21nwAvArONMcnABv67G1klPL+3H8Pz/+EIMOEcud/1vrb9QFk87/38FOTvm99rPMtauxvPRm1D8Hz52I2nu9fneggwub4Yi4hIIRhj4vFspPW26ywSOvQNS0REJMCoOIuIiAQYrdYWEREJMOqcRUREAoyKs4iISIA57xlSjDHT8OyictBa+7sDvxtjDJ5dGDrjOVJRD2vtmvMtt1q1arZ+/fpnp0+dOkWFCgU9voUUlsbXvzS+/qOx9S+Nr//kHtvVq1cfttZWL8hjC3L6shl49lXN6zB+4NkvsLH30gZ4w/vvOdWvX59Vq1adnY6Pj6dDhw4FiCNFofH1L42v/2hs/Uvj6z+5x9YYk++ha3M772pta+1SPMeczc+deE43aK213wOVTTFPvi4iIhLOfHHi79r89iDte7y37fPBskVEJEDNnTuXr7/++vwzhqlTp04Vea2EL4pzgRljngCeAKhRowbx8fFn7zt58uRvpsW3NL7+pfH1H42tfxVnfPv160diYiLlypXzbaggZ60lPT2dmJiYIo+tL4rzXn57BpUY722/Y619E3gToFWrVjbnNwr97uFfGl//0vj6j8bWv4ozvhUqVOC2227j008/9W2oIJadnc2mTZsoU6YMe/fuLfLY+mJXqrnAI8ajLZBkrdUqbRERCSvWWgYPHoy1lsaNGxdrWQXZlep9oANQzRizBxiB50TiWGv/CcTh2Y1qG55dqf5SrEQiIiJBJiMjg+XLlzNo0CCqVKlS7OWdtzhba7ud534LPF3sJCIiIkFq9OjRPPLIIz4pzFDCG4SJiASihQsXsnNngXdBDSmbN29m+/btRXrskSNHyHkwqXB0+vRpPv74Y0aMGEGpUqV8tlwVZxEJa3FxcXTp0sV1jKAV7mP3+uuvc++99/q0MIOKs4iEsfT0dPr06UOTJk1YsGABERHhd7qB7777jmuvvbbIj69Vq5YP0wSPU6dOMXXqVPr27euX5as4i0jYmjJlCj///DPz5s2jXr16ruM4sX37durUqXP+GeU3Pv30U7p37+635Yff10QREeDQoUOMGjWKW2+9lc6dO7uOI0EiKSmJ2NhYunfvTs2aNf32PCrOIhKWhg0bxsmTJ5k4caLrKBIk0tPTWbFiBbGxsXhOyOg/Ks4iEnZ+/PFH3nrrLXr27Mlll13mOo4EgcOHD9OnTx+uv/56qlat6vfnU3EWkbBiraV3795UqVKFESNGuI4jQeDIkSPs3LmTcePGUaZMmRJ5ThVnEQkrn3zyCfHx8YwePdpnB4yQ0LVv3z6GDx9O06ZNqVSpUok9r7bWFpGwkZaWRv/+/bn88sv529/+5jqOBLg9e/Zw7NgxJkyYQPny5Uv0udU5i0jYmDRpEomJibzyyiuULq3eRPK3b98+xo8fT+PGjUu8MIM6ZxEJE7/++ivPP/88d911FzfccIPrOBLAtm/fzokTJ5gwYQJRUVFOMqg4i0iJyMjIICsrq9CPS09PJy0trdjPP3jwYDIyMnjppZeKvSwJXcnJybzxxhuMGzeOyMhIZzlUnEXE7xISEmjRogWnT592miM2NpaGDRs6zSCBKyEhgQMHDjBhwgS/78d8PirOIuJ3H3/8Menp6YwZM6bQJwjYsWMHl1xySbEzREdH85e/6HTzkrfMzEw+/vhjhgwZ4rwwg4qziJSAuLg4WrduzbPPPlvox8bHx9OhQwffhxLxWrNmDTt27GDYsGGuo5ylrbVFxK8OHz7MDz/8oONXS0Cy1rJy5Uruvfde11F+Q52ziPjVl19+ibVWxVkCzvLly9mwYQNPPvmk6yi/o85ZRPxq/vz5VK9enZYtW7qOInLWqVOnOHbsGE888YTrKHlS5ywifpOVlcUXX3xB586diYhQLyCBYeHChWzcuJFevXq5jpIv/W8REb9ZuXIlR44c0SptCRiJiYlceOGFAV2YQcVZRPxo/vz5REREcPPNN7uOIsJ//vMf5s+fT/PmzV1HOS+t1hYRv4mLi6Nt27Ylcv5bkXP55ptvaN26NbfddpvrKAWizllE/OLAgQOsWrVKq7TFubi4OLZt20aNGjVcRykwdc4i4hdffPEFgIqzODVnzhxuvvlmLrjgAtdRCkXFWUTylZ2dzbBhw9iyZUuhH/vjjz9Ss2ZNrr76aj8kEzm/pUuXkp6eHnSFGVScReQcZsyYwdixY2nSpEmhz9ATFRXFU089FRDHKZbw884773D33Xdz3XXXuY5SJCrOIpKn5ORkBg8eTLt27fjmm29UZCVobNiwgWrVqgX1hojaIExE8vT8889z8OBBXnnlFRVmCRqTJ0+mfPny3Hnnna6jFIuKs4j8zrZt25g0aRI9evSgdevWruOIFMju3btp1qyZT04x6pqKs4j8Tv/+/YmKimLs2LGuo4icl7WWF154gcOHD3PTTTe5juMTKs4i8htffvkln332GUOGDOHiiy92HUfknKy17Nmzhz//+c9BceSvglJxFpGzPv/8c+655x6aNGlCnz59XMcROSdrLaNGjWL//v20adPGdRyfUnEWEQBee+017rrrLpo1a8aSJUsoW7as60gi+crOzmbDhg089NBDIbldhIqzSJjLzs6mb9++/OMf/+D2228nPj6emjVruo4lki9rLUOHDiU7O5tGjRq5juMX2s9ZJIylpKTw8MMPM2fOHJ555hkmTpxIqVKlXMcSyVdmZibx8fHExsYSHR3tOo7fqHMWCVMHDx6kY8eOfPLJJ0yaNInJkyerMEvAGzt2LHXq1AnpwgzqnEVC1o4dO/jpp5/yvC89PZ3Bgwezb98+Pv74Y+6+++4STidSOOnp6XzwwQcMHTqUiIjQ7ytVnEVC1EMPPcR3332X7/3Vq1dn8eLFIbeVq4Smt956iy5duoRFYQYVZ5GQlZKSQocOHZg0aVKe9zdo0CDkVw1K8EtNTeW1115jwIABrqOUKBVnkRAWHR2tUzZK0LLW8vnnn/Pggw+6jlLiwmP9gIiIBJUTJ04wYMAA7rvvPmrVquU6TolTcRYRkYCSlpbG6tWrGTRoUNj8xpxbeL5qEREJSEePHqVv3760bduWatWquY7jjH5zFhGRgHDkyBF27drFuHHjwv7wseqcRUTEuQMHDjB8+HAaNWqkvQhQ5ywiIo79+uuvHD58mPHjx1OhQgXXcQKCOmcREXHm0KFDvPDCCzRu3FiFOQd1ziIi4sQvv/zCkSNHmDBhAlFRUa7jBBR1ziIiUuJSUlL43//9X6644goV5jyocxYphA8//JDHH3+crKys39yenZ0dcPtjpqamcskll7iOIfI7W7Zs4ZdffuGll17CGOM6TkBScRYphA0bNnDixAn69+//m9t3795NnTp1HKXK37333us6gshvZGVl8dFHHxEbG6vCfA4qziKFZIxhwoQJv7ktPj6eDh06uAkkEiR+/PFHNmzYwLPPPus6SsALrPVwIiISkrKzs1m5ciXdunVzHSUoqHMWERG/+v7771m5ciX/+Mc/XEcJGuqcRUTEb06cOMGxY8fo2bOn6yhBRZ2zSCFkZma6jiASNOLj41m1atXvNqCU81PnLFJAp06dYubMmbRu3dp1FJGAt23bNqpWrarCXEQqziIFNH78ePbu3cvEiRNdRxEJaF988QVxcXFceeWVrqMELa3WFimAnTt3Mn78eLp27cof//hH13FEAtbSpUtp0aIFt956q+soQU2ds0gBnDlgwosvvug6ikjAWrBgAVu2bOGiiy5yHSXoqXMWOY9ly5bxwQcfMGLECOrWres6jkhAmjNnDjfeeCM333yz6yghQZ2zyDlkZWXRq1cvYmJiGDhwoOs4IgHphx9+IDU1lUqVKrmOEjLUOYucw4wZM1i7di2zZs2ifPnyruOIBJzp06fTuXNn2rRp4zpKSFHnLJKP5ORkhgwZQrt27ejatavrOCIBZ+vWrVSqVIkaNWq4jhJyVJxF8jFmzBgOHjzI5MmTdfYckVymTJlCVlaWznzmJyrOInnYunUrr7zyCj169KBVq1au44gElP3799OoUSOaNm3qOkrIUnEWyUP//v2Jiopi7NixrqOIBAxrLS+99BK7du3illtucR0npGmDMJFcFi5cyNy5cxk3bhwXX3yx6zgiAcFay969e2nfvj3XXHON6zghT52zSC6TJk0iJiaG3r17u44iEhCstYwZM4bdu3fTtm1b13HCgjpnkRxSU1NZtGgRTzzxBGXLlnUdR8Q5ay3r16+ne/fuNGzY0HWcsKHOWSSH+Ph40tLS6NSpk+soIgFh5MiRZGZmqjCXMHXOIjnMnz+fcuXKcf3117uOIuJUVlYWCxcupH///lSsWNF1nLCjzlnEy1rLvHnz6NixI+XKlXMdR8Sp8ePHU6dOHRVmR9Q5i3ht3bqVHTt20K9fP9dRRJzJyMjgvffeIzY2logI9W+uaORFvOLi4gD0e7OEtRkzZnDdddepMDumzlnEa/78+TRt2pQGDRq4jiJS4tLS0nj55ZcZMmSIDlcbAAr01cgYc6sxZosxZpsxZlAe99c1xiw2xqw1xvxkjOns+6gi/nPq1Cni4+Pp3FlvXQk/1lrmz5/Po48+qsIcIM5bnI0xpYApQCegGdDNGNMs12xDgQ+ttc2BrsDrvg4q4k+LFi0iPT1dxVnCTmpqKn379uX2228nJibGdRzxKkjnfA2wzVq7w1qbDswG7sw1jwXOnGU7GvjVdxFF/G/+/PlUqFCB9u3bu44iUmJSU1PZtm0bgwcPpnRp/coZSIy19twzGHMfcKu19nHv9MNAG2ttzxzzXAwsAKoAFYAbrbWr81jWE8ATADVq1Gg5e/bss/edPHmSCy64oNgvSPIWSuObkpJCdna2T5f5+OOP06hRI8aMGVOkx4fS+AYaja1/nDx5krfeeouHHnqI6tWru44TknK/d//85z+vttYW7DR31tpzXoD7gLdzTD8MvJZrnr5AP+/1a4EEIOJcy23ZsqXNafHixVb8J1TG97nnnrN41tT4/DJ16tQi5wqV8Q1EGlvfO3LkiF23bp09evSoxtePco8tsMqep+aeuRRkPcZeoE6O6RjvbTk9BtzqLfbfGWPKAtWAgwVYvkiBbN26ldGjR3PLLbf4/HR1ZcuW5eGHH/bpMkUC0eHDhxkxYgRjx44lOjradRzJR0GK80qgsTGmAZ6i3BXonmueXcANwAxjzGVAWeCQL4OK9OvXj6ioKGbMmEHNmjVdxxEJOvv37+fAgQO88MILOvJXgDvvBmHW2kygJ/AlsAnPVtkbjTHPGWPu8M7WD/ibMeZH4H2gh7eFF/GJr776is8//5yhQ4eqMIsUwbFjxxg9ejSNGjVSYQ4CBdo8z1obB8Tlum14jusJwB99G03EIzMzk969e9OwYUOdY1mkCHbt2sWvv/7KxIkTiYqKch1HCkDHZ5OA989//pOEhAReeuklfbCIFNLp06eZPHkyzZs31/+fIKId2ySgZGRk0K9fPz799NOztx04cIAbbriBO+/MvXu9iJzL1q1b2bJlCy+99JKO/BVkVJwlYCQnJ3P//fezYMEC7rrrLqpUqQJ4tqSOjY3Vh4tIIVhr+eijjxgwYID+7wQhFWcJCHv27KFz584kJCTw9ttv89hjj7mOJBK0NmzYwKpVqxg8eLDrKFJEKs7i3Lp16+jSpQsnTpwgLi6Om2++2XUkkaCVnZ3NqlWreOSRR1xHkWJQcRan5s+fzwMPPEDlypVZvnw5V1xxhetIIkFr1apVLF26lL59+7qOIsWkrbXFmTfffJPbb7+dRo0a8cMPP6gwixRDUlISR48epU+fPq6jiA+oOIsTY8eO5cknn+SWW25h6dKl1KpVy3UkkaC1bNky3njjDW6++WZt/BUiVJylxCUkJDB8+HD+3//7f3z22Wc6WpFIMWzZsoWqVasSGxvrOor4kIqzlChrLX369KFixYq89tprOoesSDEsXLiQefPm8Yc//EEdc4jRJ6OUqHnz5rFgwQImTZpEtWrVXMcRCVpLly7lyiuv5MYbb3QdRfxAnbOUmPT0dPr27cull17K008/7TqOSNCKj48nISGBiy66yHUU8RN1zlJi/vd//5etW7cSFxdHZGSk6zgiQemTTz6hQ4cOdOjQwXUU8SMVZ/GZvXv3MnXqVDIzM393n7WW119/nU6dOtGpUycH6USC37p160hOTj57aFsJXSrO4jMTJ05k4sSJ+XbFNWvWZNKkSSWcSiQ0vPvuu3To0IFHH33UdRQpASrO4jNnDr355Zdfuo4iElJ27dpFVFQUderUcR1FSog2CBOfSExMZPPmzXTu3Nl1FJGQMnXqVI4dO8YDDzzgOoqUIBVn8Yn58+cD6PdkER86dOgQdevW5aqrrnIdRUqYirP4RFxcHA0bNqRx48auo4iEhEmTJrFlyxZ94Q1TKs5SbGlpaSxatIjOnTvrKEUixWStZc+ePbRr14727du7jiOOqDhLsS1ZsoTU1FR9wxcpJmst48aNIzExkTZt2riOIw5pa20ptri4OMqWLauDIogUg7WWdevW0a1bNxo0aOA6jjimzlmKLS4ujo4dO1KuXDnXUUSC1pgxY8jMzFRhFkCdsxTT1q1b2bZtG7169XIdRSQoZWdnExcXR9++falQoYLrOBIg1DlLsZzZhUr7N4sUzcSJE6lXr54Ks/yGOmcplri4OC699FIuueQS11FEgkpmZibTp0+nX79+2stBfkedsxTLkiVLuOmmm1zHEAk67733Htdff70Ks+RJnbMUS1paGlWrVnUdQyRonD59mhdffJFhw4apMEu+1DmLiJQQay0LFy7k0UcfVWGWc1JxFhEpASkpKfTp04ebbrqJevXquY4jAU7FWUTEz1JTU1m/fj2DBg2iTJkyruNIEFBxFhHxo+TkZPr370/Tpk2pWbOm6zgSJFSc5Zx27dpFgwYNKF26dJ4XgFKlSjlOKRKYjh07RmJiIs899xzR0dGu40gQ0dback6xsbHs37+fgQMHEhHx++9ypUqVokePHiUfTCTAHT16lGHDhvH8889TuXJl13EkyKg4S76WLVvG7NmzGTFiBCNHjnQdRyRoHDp0iL179zJu3DgqVarkOo4EIa3WljxlZ2fTu3dvYmJiGDhwoOs4IkHjxIkTjBo1ikaNGqkwS5Gpc5Y8zZgxgzVr1jBr1izKly/vOo5IUNi7dy+JiYlMnDhRW2VLsahzlt9JTk5m8ODBtGvXjq5du7qOIxIUMjMzmTx5Mq1atVJhlmJT5ywcPnyYe++9l+TkZACSkpI4ePAg8+bN01GMRApgx44d/Pjjj4wfP951FAkR6pyFLVu2sHTpUsqWLUvdunW54ooreP3112nVqpXraCIBz1rLxx9/zG233eY6ioQQdc5y1nPPPaczTIkUwqZNm1i2bBkDBgxwHUVCjDpnEZEiyMrKYvXq1Tz22GOuo0gIUucsIlJIa9euZcGCBcTGxrqOIiFKnbOISMt1KPoAACAASURBVCEcO3aMY8eOaVW2+JWKs4hIAX377bdMmTKFjh075nk4WxFf0btLRKQANm3aRJUqVXj22WddR5EwoOIsInIeS5Ys4T//+Q9NmzbVvv9SIrRBmIjIOSxZsoSmTZty/fXXu44iYUSds4hIPr799lvWr19PjRo1XEeRMKPOWUQkD5999hnt2rWjXbt2rqNIGFJxDnDWWmbOnMnhw4eLtZzt27ezevXqPO9LTEws1rJFQk1CQgKHDx+mevXqrqNImFJxDnDff/89PXr08PvzREZGUqtWLb8/j0ig+9e//kXbtm115C9xSsU5wMXFxREREcHOnTuJjo4u8nKWLVvGn/70p3zvj4yMpGzZskVevkgo2L9/PxERETRs2NB1FAlzKs4BLi4ujnbt2hETE1Os5ZQvX56KFSv6KJVI6Hn77be56qqr6Natm+soItpaO5Dt37+fNWvW0LlzZ9dRRELa0aNHufjii2ndurXrKCKAOueA9sUXXwCoOIv40auvvsoVV1xBly5dXEcROUvFOYDFxcVRq1YtrrzyStdRRELSnj17aNOmDW3atHEdReQ3tFo7QGVkZLBgwQI6deqkwwWK+MELL7zA1q1bVZglIKlzDlDfffcdSUlJWqUt4mPWWlavXk337t2pW7eu6zgieVLnHKDmz59P6dKlufHGG11HEQkpL774IhkZGSrMEtDUOQeouLg42rdvT6VKlVxHEQkJ2dnZfP755/Tq1Yty5cq5jiNyTuqcA9CePXv46aeftEpbxIemTJlCvXr1VJglKKhzDhDJycmkpqYC8PHHHwPahUrEF7Kysnjrrbfo2bOnNq6UoKHiHAAWLlzIbbfdxunTp8/eVrduXZo1a+YwlUho+OCDD+jQoYMKswQVFWfHMjIy+Mc//kFMTAz9+vU7e/s111yjDxORYkhPT2fs2LEMHz6ciAj9gifBRcXZsTfeeIPNmzczd+5cbr/9dtdxREJCdnY2S5Ys4dFHH1VhlqCkd61Dhw8fZsSIEdx0003cdtttruOIhITU1FT69OlD+/btadCgges4IkWiztmhESNGcOLECSZNmqRV2CI+kJKSwqZNmxg4cKC2ypagps7ZkfXr1/PPf/6Tv//97/zhD39wHUck6J04cYIBAwZQv359ateu7TqOSLGocy4hq1at4p577jm7RfapU6eIjo5m5MiRboOJhICkpCR++eUXRo4cyYUXXug6jkixqTiXkISEBHbv3k337t3PHvWre/fu+iARKabjx48zZMgQxowZQ9WqVV3HEfEJFecSNnr0aC655BLXMURCwuHDh9m1axfjxo0jOjradRwRn9FvziISlFJTUxk5ciSNGzdWYZaQo85ZRILOvn372LRpE5MmTSIyMtJ1HBGfU+csIkElOzubV155hbZt26owS8hS5ywiQeOXX37h+++/58UXX3QdRcSvCtQ5G2NuNcZsMcZsM8YMymeeB4wxCcaYjcaYWb6NKSICc+bM4Z577nEdQ8Tvzts5G2NKAVOAm4A9wEpjzFxrbUKOeRoDg4E/WmuPGWMu8ldgEQk/W7Zs4auvvqJv376uo4iUiIJ0ztcA26y1O6y16cBs4M5c8/wNmGKtPQZgrT3o25giEq6ysrJYs2YNTz31lOsoIiWmIMW5NrA7x/Qe7205NQGaGGOWG2O+N8bc6quAIhK+fvrpJ2bNmkW3bt0oXVqbyEj48NW7vTTQGOgAxABLjTFXWGuP55zJGPME8ARAjRo1iI+PP3vfyZMnfzMdajZt2gTA999/z65du0r8+UN9fF3T+PpeUlISiYmJ3HnnnRpbP9J713+KM7YFKc57gTo5pmO8t+W0B/jBWpsBJBpjfsZTrFfmnMla+ybwJkCrVq1shw4dzt4XHx9PzulQ8N5777FmzRrAc/hOgLZt2zo5Qlgojm8g0fj61ooVK1i8eDGjRo3S2PqZxtd/ijO2BSnOK4HGxpgGeIpyV6B7rnk+BboB040x1fCs5t5RpEQhpHfv3iQlJZ09dV3Dhg2pXr2641QigW3jxo06KYyEvfP+5mytzQR6Al8Cm4APrbUbjTHPGWPu8M72JXDEGJMALAYGWGuP+Ct0sLDW8tRTT5GcnExycjLbtm2jYsWKrmOJBKzly5czd+5cmjRponOcS1gr0G/O1to4IC7XbcNzXLdAX+9FRKTQli5dSpMmTWjXrp0Ks4Q9Hb5TRJxbtWoVa9asoWbNmirMIqg4i4hjn3/+ObVq1aJ3796uo4gEDBVnEXFm+/bt7Nu3j1q1armOIhJQVJxFxIkPPviA06dP88QTT7iOIhJwVJxFpMQdOXKEzMxMmjVr5jqKSEDS8fBEpETNmDGDRo0a8eCDD7qOIhKw1DmLSIlJSkqievXqtG/f3nUUkYCmzllESsTrr79Oo0aN6NKli+soIgFPxVlE/G737t20bt2a1q1bu44iEhS0WltE/Orll19m8+bNKswihaDOWUT8wlrLihUr6Nq1K7Vr5z4FvIicizpnEfGLiRMnkpmZqcIsUgTqnEXEp6y1fPLJJzz99NOULVvWdRyRoKTOWUR86s0336RevXoqzCLFoM7ZxzIzM89e95xJUyQ8ZGVl8frrr9OzZ0+dWUqkmNQ5+9Ds2bMpU6YMkZGRREZGcuzYMUqVKuU6lkiJmDNnDh07dlRhFvEBdc4+tG3bNqy1jBw5klKlSmGMoWvXrq5jifhVRkYGzz33HCNGjKB0aX2kiPiC/if5wbPPPqsPKQkL2dnZLF++nEcffVTveREf0mptESmStLQ0+vTpQ8uWLWnUqJHrOCIhRV91RaTQUlNT2bJlC/3796dixYqu44iEHHXOIlIop06dYsCAAdSqVYs6deq4jiMSktQ5+9Dp06ddRxDxqxMnTpCYmMiwYcO46KKLXMcRCVnqnH3k5MmTvPPOO7Rt21YbxkhIOnHiBIMGDaJWrVrUqFHDdRyRkKYq4iMvvPAC+/btY86cOa6jiPjc0aNH2bFjB2PHjiU6Otp1HJGQp87ZBxITE3nppZd48MEHadu2res4Ij6Vnp7O8OHDady4sQqzSAlR5+wDAwcOpFSpUrzwwguuo4j41IEDB1i3bh2vvPKKfq4RKUHqnItpyZIlfPTRRwwaNIiYmBjXcUR8xlrLq6++Svv27VWYRUqY/scVg7WWPn36ULduXfr37+86jojP7N69m/j4eJ5//nnXUUTCkjrnYkhJSWHt2rX87W9/o1y5cq7jiPjMp59+yv333+86hkjYUufsA1FRUa4jiPjE9u3bmTt3Ln369HEdRSSsqXMWEcBzdqk1a9bQs2dP11FEwp46ZxFh48aNfPjhh4waNcp1FBFBnbNI2Dt48CDHjx9n+PDhrqOIiJeKs0gYW716Na+++irt2rWjVKlSruOIiJeKs0iY2rBhAxUrVmT06NEYY1zHEZEcVJxFwtCKFSv49NNPady4sQqzSABScRYJM8uWLSMmJoZnn31WhVkkQKk4i4SRn376iRUrVlCrVi0VZpEApuIsEibi4uKIjo6mX79+rqOIyHmoOIuEgd27d/PLL79Qr14911FEpABUnEVC3EcffcSRI0f4n//5H9dRRKSAVJxFQlhSUhKpqalcffXVrqOISCHo8J0iIerdd9+ldu3aPPzww66jiEghqXMWCUHJyclceOGFdOzY0XUUESkCdc4iIWbq1KnExMTQpUsX11FEpIhUnEVCyM6dO2nVqhUtW7Z0HUVEikGrtYshOTkZQCcMkIAwefJkEhISVJhFQoA652L48MMPAbjpppscJ5FwZq3l22+/5YEHHuDiiy92HUdEfECdcxFZa3nnnXdo3bo1V1xxhes4EsZeffVVMjMzVZhFQog65yJavXo169ev54033nAdRcKUtZZ///vfPPXUU0RFRbmOIyI+pM65iKZNm0bZsmXp2rWr6ygSpqZPn069evVUmEVCkDrnIkhNTWXWrFncd999VK5c2XUcCTPZ2dm8+uqr9OrVS2eWEglR6pyLYM6cOSQlJfHXv/7VdRQJQ//5z3/o2LGjCrNICFNxLoJp06bRoEEDrr/+etdRJIxkZmYybNgwbrnlFq688krXcUTEj1ScCykxMZFFixbx17/+lYgIDZ+UjKysLFasWMHDDz+s35hFwoCqSyHNmDEDYwyPPvqo6ygSJtLT0+nfvz+XXXYZTZo0cR1HREqANggrhKysLKZPn87NN99MnTp1XMeRMJCWlsbPP/9M7969qVKlius4IlJC1DkXwtdff83u3bu1IZiUiJSUFAYMGED16tWpV6+e6zgiUoLUORfCtGnTqFq1KnfeeafrKBLiTp06xfbt2xkyZIiO/CUShtQ5F9CRI0f45JNPeOihh7RBjvjVqVOnGDhwIDVr1lRhFglT6pwLaNasWaSnp2uVtvjV8ePH2bJlC2PHjiU6Otp1HBFxRJ1zAU2bNo2WLVty1VVXuY4iISozM5Phw4fTpEkTFWaRMKfOuQDWrFnDunXrmDJliusoEqIOHTrEDz/8wKRJk3R+cBFR51wQ06ZNIyoqim7durmOIiHIWstrr71Ghw4dVJhFBFDnnKfFixfz73//++z0rFmzuPfee7Wfqfjc3r17+fLLLxk1apTrKCISQFScczlw4AB33XUXWVlZlC9fHoALLriAZ555xnEyCTXWWubOnUuPHj1cRxGRAKPinMvQoUNJSUlh48aNOlSi+E1iYiIffPABgwYNch1FRAKQfnPOYe3atbzzzjs888wzKsziN6dPn2bdunX07dvXdRQRCVAqzl7WWnr16sWFF17IsGHDXMeRELVp0yZGjRrF3XffTZkyZVzHEZEApdXaXh999BHLli1j6tSpVK5c2XUcCUH79+8nKSmJ0aNHu44iIgFOnTOQmprKgAEDuOqqq3jsscdcx5EQtG7dOiZPnsw111yj3aVE5LzUOQPLly9n586dTJ48WR+c4nMbNmygQoUKPP/880RE6PuwiJyfPinwnKcZ4KKLLnKcRELNmjVr+Oijj2jUqJEKs4gUmD4tRPxk+fLlVKtWjREjRmCMcR1HRIKIirOIH2zevJlvvvmGOnXqqDCLSKGpOIv42IIFC4iIiCA2NlaFWUSKpEDF2RhzqzFmizFmmzEm30MaGWPuNcZYY0wr30UUCR4HDhxg8+bNOoiNiBTLeYuzMaYUMAXoBDQDuhljmuUxX0WgF/CDr0OKBINPP/2UX375RcdhF5FiK0jnfA2wzVq7w1qbDswG7sxjvtHAi0CaD/OJBIXU1FSSk5Np06aN6ygiEgIKUpxrA7tzTO/x3naWMaYFUMdaO8+H2USCwvvvv8/69et55JFHXEcRkRBR7IOQGGMigIlAjwLM+wTwBECNGjWIj48/e9/Jkyd/M12SfvzxR8CzT+rp06edZPA3l+Mbyk6dOsXOnTu5/PLLNb5+oveuf2l8/ac4Y1uQ4rwXqJNjOsZ72xkVgcuBeO+WqTWBucaYO6y1q3IuyFr7JvAmQKtWrWyHDh3O3hcfH0/O6ZJ0piC3aNGCa6+91kkGf3M5vqFq2rRpVK1alUGDBml8/Uhj618aX/8pztgWpDivBBobYxrgKcpdge5n7rTWJgHVzkwbY+KB/rkLs0go2bFjBy1atODqq692HUVEQtB5f3O21mYCPYEvgU3Ah9bajcaY54wxd/g7YEnIzMwE0D6pUiBTpkxh48aNKswi4jcF+s3ZWhsHxOW6bXg+83YofqyStXnzZgAuueQSx0kk0C1btoz7779fx2EXEb/SEcKAtWvXUqtWLX3gyjm98cYbZGRk6H0iIn6nU0biKc4tWrRwHUMClLWW2bNn8/jjjxMZGek6joiEgbDvnFNSUti8eTPNmzd3HUUC1KxZs6hfv74Ks4iUmLDvnNevX092draKs/xOdnY2r7zyCr169aJUqVKu44hIGAn7znnt2rUAKs7yOwsWLODPf/6zCrOIlDgV57VrqVKlCvXq1XMdRQJEVlYWQ4cO5brrrtOXNhFxQsV57Vquvvpq7eMsgKcwr1mzhgcffJDy5cu7jiMiYSqsi3NmZibr169XdyQAZGRkMGDAAOrVq8dll13mOo6IhLGw3iBs8+bNpKWlaTcq4fTp02zdupWePXtqP2YRcS6sO2dtDCYAaWlpDBgwgMqVK+socSISEMK6c16zZg3lypXj0ksvdR1FHElJSWHbtm0MGjSIWrVquY4jIgKoc+bKK6/UrjJhKi0tjYEDB3LRRRepMItIQAnb4mytZd26dVqlHaaSk5NZvXo1Y8eOpWbNmq7jiIj8RtgW58TERJKSklScw1B2djbDhg2jadOmVKpUyXUcEZHfCdvfnLUxWHg6cuQIS5cuZdKkSUREhO13UxEJcGH76bR27VpKlSrFFVdc4TqKlKDXX3+dG264QYVZRAJaWHfOzZo1o2zZsq6jSAnYv38/n332GcOGDXMdRUTkvMKyfcjKyuK7776jdevWrqNICbDW8vnnn/Pwww+7jiIiUiBh2Tn/8MMPHDt2jFtvvdV1FPGznTt3MnPmTHXMIhJUwrJzjouLo1SpUtx0002uo4gfpaWl8dNPPzFw4EDXUURECiVsi3O7du2oXLmy6yjiJz///DPDhw/ntttuIyoqynUcEZFCCbvivG/fPtauXUvnzp1dRxE/+fXXX0lKSmLs2LE6FaiIBKWwK85ffPEFgIpziFq/fj2TJ0+mRYsWlC4dlptUiEgICLtPr7i4OGrXrq39m0PQhg0bKFu2LOPGjdN+zCIS1MLqEywjI4MFCxbQqVMnre4MMRs2bODDDz+kYcOGKswiEvTC6lPs22+/JTk5Wau0Q8x3331HhQoVGDVqlAqziISEsPokmz9/PpGRkdxwww2uo4iP7Nixg8WLF1O/fn2tDRGRkBFWxTkuLo727dvrTEQh4uuvvyYlJYXBgwerMItISAn6DcIOHz7MkSNHCjTf+vXrmTBhQgmkEn87evQoGzZs0FoQEQlJQV2cU1NTqVevHikpKQV+TJcuXfyYSErCf/7zH6Kjo+nVq5frKCIifhHUxTktLY2UlBQefvhhOnXqdN75L7roIi677LISSCb+kpaWxtGjR7nttttcRxER8ZugLs5ntGzZkm7durmOIX724YcfUrZsWR555BHXUURE/CokirOEvuTkZCpVqqQziYlIWFBxloD3f//3f5QvX57777/fdRQRkRKh4iwBbevWrbRo0UKHWxWRsBJ0+zmPGTOGqKgooqKiqFGjBoCOChWipk6dSkJCggqziISdoOqcrbVMnz6dJk2anN1aNzIykvvuu89xMvG1xYsXc++991KtWjXXUURESlxQFeeff/6ZHTt28Prrr/P3v//ddRzxk7fffpu6deuqMItI2Aqq4hwXFwdQoH2aJfhYa3nvvffo0aOHzsUsImEtqH6snT9/Ps2aNaN+/fquo4gffPTRR9SvX1+FWUTCXtAU55MnT7JkyRJ1zSHIWsvLL7/MXXfdxZ/+9CfXcUREnAua4rxo0SLS09N1LuYQtHjxYq6//noiIyNdRxERCQhBU5zj4uK44IILaN++veso4iPZ2dkMHTqUVq1a0apVK9dxREQCRlD8uGetZf78+dx0002UKVPGdRzxgaysLNavX0/Xrl11fm0RkVyConNOSEhg165d+r05RGRkZBAbG0v16tW5/PLLXccREQk4QdE5axeq0JGens62bdt48sknqV27tus4IiIBKSg657i4OK688kpiYmJcR5FiOH36NAMHDqR8+fI0btzYdRwRkYAV8MU5OTmZb775RltpB7nU1FQ2b97MgAEDtJ+6iMh5BHxxTkxMJDMzk5YtW7qOIkWUkZHBgAEDqFatmlZli4gUQFD85gxQqlQp1xGkCE6cOMGaNWsYN24cFStWdB1HRCQoBHznLMHLWsvIkSNp1qyZCrOISCEETecsweXYsWN89dVXTJgwQefbFhEpJH1qil+8+eab3HzzzSrMIiJFoM5ZfOrgwYN8+OGHxMbGuo4iIhK01NaIz1hrmTdvHn/5y19cRxERCWrqnMUn9uzZw5tvvslzzz3nOoqISNBT5yzFlpqayoYNGxgyZIjrKCIiIUHFWYpl+/btPPvss9xyyy2ULVvWdRwRkZCg4ixFtmfPHpKSknjxxRcxxriOIyISMgLiN+fs7GwSEhLIzs7+3X3bt293kEjOZ9OmTUyfPp2xY8dSunRAvI1EREJGQHyqLl26lKeffvqc8+gIU4Fj48aNlClThnHjxumwqiIifhAQxfnkyZMATJ06laZNm/7u/nLlyunEFwFi8+bNzJo1i9GjR+sAIyIifhIQxfmMFi1a0KpVK9cxJB8rVqygSpUqjBkzRr8xi4j4kVofKZA9e/bwxRdf0KhRIxVmERE/C6jOWQLTkiVLqFixIsOGDVNhFhEpAeqc5ZxOnDjB2rVrad68uQqziEgJUecs+Zo/fz6RkZH07t3bdRQRkbCizlnylJ6ezqFDh7jxxhtdRxERCTvqnOV35syZQ3Z2No888ojrKCIiYUnFWX4jKSmJCy64gJtvvtl1FBGRsKXiLGe99957RERE0L17d9dRRETCmoqzAJ4jf7Vo0YJmzZq5jiIiEva0QZjwzjvvsHHjRhVmEZEAoc45zH399dfcfffdVK1a1XUUERHxUuccxmbOnMnp06dVmEVEAow65zA1c+ZMunfvrnMxi4gEIHXOYWju3LnUrVtXhVlEJEAVqDgbY241xmwxxmwzxgzK4/6+xpgEY8xPxpivjTH1fB9Vistay8svv8wtt9xChw4dXMcREZF8nLc4G2NKAVOATkAzoJsxJvdmvWuBVtbaK4GPgPG+DirFt3z5ctq3b09UVJTrKCIicg4F6ZyvAbZZa3dYa9OB2cCdOWew1i621qZ4J78HYnwbU4ojOzubadOmcdlll9GmTRvXcURE5DwK8qNjbWB3juk9wLk+4R8D5ud1hzHmCeAJgBo1ahAfHw/A+vXrAVi9ejUnT54sQCQpqKysLHbt2kXr1q3PjrP43smTJ8++n8W3NLb+pfH1n+KMrU+3CDLGPAS0Aq7P635r7ZvAmwCtWrWyZ373PFOQW7ZsSatWrXwZKaxlZmYyZMgQnn76aRITE/U7sx/Fx8drfP1EY+tfGl//Kc7YFmS19l6gTo7pGO9tv2GMuRF4FrjDWnu6SGnEZzIyMti2bRuPPfYY9epp+zwRkWBSkOK8EmhsjGlgjCkDdAXm5pzBGNMcmIqnMB/0fUwpjPT0dAYOHEhkZCSXXnqp6zgiIlJI512tba3NNMb0BL4ESgHTrLUbjTHPAaustXOBCcAFwL+NMQC7rLV3+DG35CMtLY3NmzfTv39/ateu7TqOiIgUQYF+c7bWxgFxuW4bnuP6jT7OJUWQlZXFwIEDGTBggAqziEgQ0yGiQsSpU6f4/vvvGTduHBUqVHAdR0REikGH7wwRzz33HJdffrkKs4hICFDnHOSOHz/OvHnzeOGFF/D+3i8iIkFOnXOQe+edd+jUqZMKs4hICFHnHKQOHz7MzJkz6devn+soIiLiY+qcg5C1li+++IK//e1vrqOIiIgfqDgHmV9//ZUhQ4bw0EMPUbFiRddxRETED1Scg8ipU6dISEhg+PDh559ZRESClopzkPjll18YMmQIHTt2pFy5cq7jiIiIH6k4B4E9e/Zw/PhxJkyYQESE/mQiIqFOn/QB7ueff2bSpEn84Q9/oEyZMq7jiIhICVBxDmAJCQkAvPjii0RGRjpOIyIiJUXFOUBt376dmTNn0rBhQ0qX1u7oIiLhRMU5AK1evZrTp08zduxYSpUq5TqOiIiUMBXnAHPw4EE+//xzLrvsMm38JSISprS+NIB88803lC5dmpEjR7qOIiIiDqk1CxCpqamsXLmSNm3auI4iIiKOqXMOAF999RXp6en06dPHdRQREQkA6pwdy8jI4MCBA3Tp0sV1FBERCRDqnB2aO3cuJ0+e5KGHHnIdRUREAoiKsyPHjh2jQoUK3HHHHa6jiIhIgFFxdmD27Nmkp6fzyCOPuI4iIiIBSMW5hG3cuJHmzZtz6aWXuo4iIiIBShuElaCZM2eyceNGFWYRETkndc4lZMGCBdx5551ER0e7jiIiIgFOnXMJmD17NqdPn1ZhFhGRAlHn7GczZszgwQcf1CkfRUSkwNQ5+9EXX3xBTEyMCrOIiBSKOmc/sNby8ssv8/e//50KFSq4jiMiIkFGnbOPWWtZuXIl1157rQqziIgUiYqzD2VnZzNixAjq1q3LH//4R9dxREQkSKk4+0h2djY///wzd911FzVr1nQdR0REgpiKsw9kZWUxePBgSpcuTYsWLVzHERGRIKcNwoopMzOT7du385e//IVGjRq5jiMiIiFAnXMxZGRkMHDgQIwxNG3a1HUcEREJEeqci+j06dNs3LiRfv36Ubt2bddxREQkhKhzLoLs7GxiY2O58MILVZhFRMTn1DkXUkpKCkuXLmXcuHGUK1fOdRwREQlB6pwL6fnnn+eqq65SYRYREb9R51xAycnJfPLJJ4wZMwZjjOs4IiISwtQ5F9D06dPp0qWLCrOIiPidOufzOHr0KG+//TYDBw50HUVERMKEOudzyM7O5quvvuLJJ590HUVERMKIinM+9u/fT2xsLA888ADR0dGu44iISBhRcc7DiRMn2Lx5MyNHjtRvzCIiUuJUnHPZtWsXQ4YMoX379jofs4iIOKHinMPu3bs5fvw4L730EqVLa1s5ERFxQ8XZa/v27UyaNImmTZsSFRXlOo6IiIQxtYfA5s2bAXjxxReJjIx0nEZERMJd2HfOu3btYvr06TRu3FiFWUREAkJYd87r1q0jIiKCcePGERER9t9TREQkQIRtRTp+/DiffPIJl19+uQqziIgElLDsnL///nvS09MZNWqU6ygiIiK/E3YtY3p6Ot999x1/+tOfXEcRERHJH4lCkwAABwRJREFUU1h1zosWLeL48eP06dPHdRQREZF8hU3nnJGRwb59+7jnnntcRxERETmnsOic582bx6FDh+jRo4frKCIiIucV8sX58OHDVKhQgS5duriOIiIiUiAhXZz//e9/c+LECf7617+6jiIiIlJgIVucf/rpJ5o3b06jRo1cRxERESmUkNwg7P3332f9+vUqzCIiEpRCrnOeP38+Xbp0oVKlSq6jiIiIFElIFeePP/6YiIgIFWYREQlqIVOcZ8yYQbdu3XQuZhERCXoh8ZvzokWLqFmzpgqziIiEhKDunK21TJw4kccff5zo6GjXcURERHwiaDtnay0//fQTrVu3VmEWEZGQEpTF2VrL6NGjqVKlCtddd53rOCIiIj4VdKu1s7Oz2bFjB506daJu3bqu44iIiPhcUHXO2dnZDB06lIyMDFq3bu06joiIiF8ETeeclZXF9u3beeihh7jssstcxxEREfGboOicMzMziY2NJSsri2bNmrmOIyIi4lcB3zlnZGTw448/0q9fPy6++GLXcURERPwuoDtnay2DBg2iatWqKswiIhI2ArZzTktLY+HChTz//POULVvWdRwREZESE7Cd8/jx42nevLkKs4iIhJ0CFWdjzK3GmC3GmG3GmEF53B9ljPnAe/8Pxpj6RQ108uRJ3nnnHYYNG0bt2rWLuhgREZGgdd7ibIwpBUwBOgHNgG7GmNybTD8GHLPWNgImAS8WNdC7777LHXfcgTGmqIsQEREJagXpnK8Btllrd1hr04HZwJ255rkT+D/v9Y+AG0wRquu0adP4+9//TvXq1Qv7UBERkZBRkOJcG9idY3qP97Y857HWZgJJwIWFDXP//fcX9iEiIiIhp0S31jbGPAE8AVCjRg3i4+MBz77MI0aM4NSpU2dvE986efKkxtaPNL7+o7H1L42v/xRnbAtSnPcCdXJMx3hvy2uePcaY0kA0cCT3gqy1bwJvArRq1cp26NDh7H1VqlQh57T4Vnx8vMbXjzS+/qOx9S+Nr/8UZ2wLslp7JdDYGNPAGFMG6ArMzTXPXOBR7/X7gEXWWlukRCIiImHuvJ2ztTbTGNMT+BIoBUyz9v+3d/cgdpRhFMf/R1REjB+wCBaaIBgwxMKQIjZ+oIhssRaCKASJBIsIFipWFgYtRQtBiBFFFBS1kQUVC4ksiCssBEOSQqLGEBQSUdMERfRYzBTL4u68u3G+7j0/GJi7997h4TDMc+ed2Xl9TNLzwJLteeAN4B1JJ4BfqRp4REREbID6OsGVdBb4cdmfZoBfeilmOiTfdiXf9iTbdiXf9qzMdrPton9H6q05ryRpyfbOvuuYVMm3Xcm3Pcm2Xcm3PReS7WAf3xkRETGt0pwjIiIGZkjN+WDfBUy45Nuu5NueZNuu5NueDWc7mGvOERERURnSmXNERETQQ3PucvrJaVSQ71OSjks6IulzSZv7qHOMmrJd9rkHJFlS7oBdh5J8JT1Y77/HJL3bdY1jVXBcuEHSIUmH62PDbB91jpGkNyWdkXR0lfcl6ZU6+yOSdhRt2HZnC9VDTL4DbgQuBb4Btq34zOPAgXr9IeD9Lmsc81KY713A5fX6vuT7/2Vbf24TsAAsAjv7rnssS+G+exNwGLimfn1t33WPYSnM9iCwr17fBpzsu+6xLMDtwA7g6CrvzwKfAgJ2AV+XbLfrM+fOpp+cUo352j5k+3z9cpHqWenRrGTfBXiBaj7zP7osbgKU5PsY8Krt3wBsn+m4xrEqydbAlfX6VcBPHdY3arYXqJ6MuZr7gbddWQSulnRd03a7bs6dTT85pUryXW4v1S+6aNaYbT1cdb3tj7ssbEKU7Ltbga2SvpS0KOm+zqobt5Js9wO7JZ0GPgGe6Ka0qbDe4zLQ8ZSRMRySdgM7gTv6rmUSSLoIeBnY03Mpk+xiqqHtO6lGfBYk3WL7916rmgwPA2/ZfknSbVRzJWy3/U/fhU2rrs+c1zP9JGtNPxn/qSRfJN0DPAvM2f6zo9rGrinbTcB24AtJJ6muLc3nprBiJfvuaWDe9l+2fwC+pWrWsbaSbPcCHwDY/gq4jOq50HHhio7LK3XdnDP9ZLsa85V0K/AaVWPONbtya2Zr+5ztGdtbbG+hup4/Z3upn3JHp+TY8BHVWTOSZqiGub/vssiRKsn2FHA3gKSbqZrz2U6rnFzzwCP1Xdu7gHO2f276UqfD2s70k60qzPdF4Argw/o+u1O253oreiQKs40NKsz3M+BeSceBv4FnbGdUrUFhtk8Dr0t6kurmsD05KSoj6T2qH40z9TX754BLAGwfoLqGPwucAM4DjxZtN/lHREQMS54QFhERMTBpzhEREQOT5hwRETEwac4REREDk+YcERExMGnOERERA5PmHBERMTBpzhEREQPzL1uX8PJ7gtP4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1gEnKudKsUN"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDRfWKqqKsUO"
      },
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0YbyTyCKsUO"
      },
      "source": [
        "# Define the Model \n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
        "model_1.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNSnr8K2KsUO",
        "outputId": "dbdac35e-f90e-476f-f586-d3252aeea91d"
      },
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaRvH6e9KsUP"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 121 parameters?  Does that make sense?\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SOqnVrqKsUP",
        "outputId": "32067eae-67b0-4fa2-afa5-19cdfa955600"
      },
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
        "# the fit function returns the run history. \n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.8467 - accuracy: 0.3375 - val_loss: 0.8189 - val_accuracy: 0.3594\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8275 - accuracy: 0.3320 - val_loss: 0.8005 - val_accuracy: 0.3594\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8057 - accuracy: 0.3365 - val_loss: 0.7840 - val_accuracy: 0.3594\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7824 - accuracy: 0.3652 - val_loss: 0.7691 - val_accuracy: 0.3594\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.3448 - val_loss: 0.7557 - val_accuracy: 0.3594\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.3362 - val_loss: 0.7436 - val_accuracy: 0.3594\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.3613 - val_loss: 0.7328 - val_accuracy: 0.3542\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.3496 - val_loss: 0.7231 - val_accuracy: 0.3646\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7225 - accuracy: 0.3500 - val_loss: 0.7144 - val_accuracy: 0.3594\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.3776 - val_loss: 0.7065 - val_accuracy: 0.4115\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.4268 - val_loss: 0.6995 - val_accuracy: 0.4948\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.4230 - val_loss: 0.6932 - val_accuracy: 0.5417\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4869 - val_loss: 0.6874 - val_accuracy: 0.5312\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5553 - val_loss: 0.6823 - val_accuracy: 0.6302\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6084 - val_loss: 0.6777 - val_accuracy: 0.6406\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.6733 - val_loss: 0.6735 - val_accuracy: 0.6406\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6848 - val_loss: 0.6697 - val_accuracy: 0.6562\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6621 - val_loss: 0.6662 - val_accuracy: 0.6615\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6785 - val_loss: 0.6631 - val_accuracy: 0.6458\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.6570 - val_loss: 0.6603 - val_accuracy: 0.6458\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6505 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6692 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6389 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6328 - val_loss: 0.6511 - val_accuracy: 0.6302\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6951 - val_loss: 0.6493 - val_accuracy: 0.6302\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6659 - val_loss: 0.6476 - val_accuracy: 0.6354\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6673 - val_loss: 0.6460 - val_accuracy: 0.6406\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6637 - val_loss: 0.6446 - val_accuracy: 0.6354\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6608 - val_loss: 0.6432 - val_accuracy: 0.6354\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6706 - val_loss: 0.6419 - val_accuracy: 0.6354\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6897 - val_loss: 0.6407 - val_accuracy: 0.6354\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6716 - val_loss: 0.6396 - val_accuracy: 0.6354\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6684 - val_loss: 0.6386 - val_accuracy: 0.6354\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.6825 - val_loss: 0.6376 - val_accuracy: 0.6406\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6624 - val_loss: 0.6366 - val_accuracy: 0.6406\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6848 - val_loss: 0.6357 - val_accuracy: 0.6406\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6680 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6770 - val_loss: 0.6340 - val_accuracy: 0.6458\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6790 - val_loss: 0.6332 - val_accuracy: 0.6458\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6657 - val_loss: 0.6324 - val_accuracy: 0.6458\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6448 - val_loss: 0.6316 - val_accuracy: 0.6458\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6485 - val_loss: 0.6309 - val_accuracy: 0.6458\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6515 - val_loss: 0.6302 - val_accuracy: 0.6458\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6692 - val_loss: 0.6295 - val_accuracy: 0.6458\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6590 - val_loss: 0.6288 - val_accuracy: 0.6458\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6829 - val_loss: 0.6281 - val_accuracy: 0.6458\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6609 - val_loss: 0.6275 - val_accuracy: 0.6458\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6542 - val_loss: 0.6269 - val_accuracy: 0.6458\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6431 - val_loss: 0.6262 - val_accuracy: 0.6458\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.6721 - val_loss: 0.6256 - val_accuracy: 0.6458\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.6587 - val_loss: 0.6250 - val_accuracy: 0.6458\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6761 - val_loss: 0.6244 - val_accuracy: 0.6458\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6584 - val_loss: 0.6238 - val_accuracy: 0.6458\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6708 - val_loss: 0.6232 - val_accuracy: 0.6458\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6509 - val_loss: 0.6226 - val_accuracy: 0.6458\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6645 - val_loss: 0.6220 - val_accuracy: 0.6458\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6727 - val_loss: 0.6215 - val_accuracy: 0.6458\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6493 - val_loss: 0.6209 - val_accuracy: 0.6458\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6437 - val_loss: 0.6203 - val_accuracy: 0.6458\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6457 - val_loss: 0.6198 - val_accuracy: 0.6458\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6676 - val_loss: 0.6192 - val_accuracy: 0.6458\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.5954 - val_loss: 0.6187 - val_accuracy: 0.6458\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6789 - val_loss: 0.6181 - val_accuracy: 0.6458\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6697 - val_loss: 0.6176 - val_accuracy: 0.6458\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6590 - val_loss: 0.6170 - val_accuracy: 0.6458\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6613 - val_loss: 0.6165 - val_accuracy: 0.6458\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.6517 - val_loss: 0.6159 - val_accuracy: 0.6458\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6456 - val_loss: 0.6154 - val_accuracy: 0.6458\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.6608 - val_loss: 0.6148 - val_accuracy: 0.6458\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6646 - val_loss: 0.6143 - val_accuracy: 0.6458\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6881 - val_loss: 0.6138 - val_accuracy: 0.6458\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6449 - val_loss: 0.6132 - val_accuracy: 0.6458\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6478 - val_loss: 0.6127 - val_accuracy: 0.6458\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6590 - val_loss: 0.6122 - val_accuracy: 0.6458\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6302 - val_loss: 0.6117 - val_accuracy: 0.6458\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.6400 - val_loss: 0.6111 - val_accuracy: 0.6458\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6661 - val_loss: 0.6106 - val_accuracy: 0.6458\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6785 - val_loss: 0.6101 - val_accuracy: 0.6458\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6665 - val_loss: 0.6096 - val_accuracy: 0.6458\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6666 - val_loss: 0.6090 - val_accuracy: 0.6458\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6338 - val_loss: 0.6085 - val_accuracy: 0.6458\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.6642 - val_loss: 0.6080 - val_accuracy: 0.6406\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6466 - val_loss: 0.6075 - val_accuracy: 0.6406\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6343 - val_loss: 0.6070 - val_accuracy: 0.6406\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.6713 - val_loss: 0.6065 - val_accuracy: 0.6406\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6679 - val_loss: 0.6060 - val_accuracy: 0.6406\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6708 - val_loss: 0.6055 - val_accuracy: 0.6406\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6289 - val_loss: 0.6050 - val_accuracy: 0.6406\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6475 - val_loss: 0.6044 - val_accuracy: 0.6406\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6489 - val_loss: 0.6039 - val_accuracy: 0.6406\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6658 - val_loss: 0.6034 - val_accuracy: 0.6406\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6905 - val_loss: 0.6029 - val_accuracy: 0.6406\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.6573 - val_loss: 0.6024 - val_accuracy: 0.6406\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6394 - val_loss: 0.6019 - val_accuracy: 0.6406\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.6893 - val_loss: 0.6014 - val_accuracy: 0.6406\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6740 - val_loss: 0.6010 - val_accuracy: 0.6406\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.6467 - val_loss: 0.6005 - val_accuracy: 0.6406\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6843 - val_loss: 0.6000 - val_accuracy: 0.6406\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6599 - val_loss: 0.5995 - val_accuracy: 0.6406\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6332 - val_loss: 0.5990 - val_accuracy: 0.6406\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6753 - val_loss: 0.5985 - val_accuracy: 0.6406\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6675 - val_loss: 0.5980 - val_accuracy: 0.6406\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6726 - val_loss: 0.5975 - val_accuracy: 0.6406\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6516 - val_loss: 0.5970 - val_accuracy: 0.6406\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.6737 - val_loss: 0.5966 - val_accuracy: 0.6406\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6632 - val_loss: 0.5961 - val_accuracy: 0.6406\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.6611 - val_loss: 0.5956 - val_accuracy: 0.6406\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6428 - val_loss: 0.5951 - val_accuracy: 0.6406\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.6562 - val_loss: 0.5947 - val_accuracy: 0.6406\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.6619 - val_loss: 0.5942 - val_accuracy: 0.6406\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.6625 - val_loss: 0.5937 - val_accuracy: 0.6406\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.6767 - val_loss: 0.5932 - val_accuracy: 0.6406\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.6943 - val_loss: 0.5928 - val_accuracy: 0.6406\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.6735 - val_loss: 0.5923 - val_accuracy: 0.6406\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6933 - val_loss: 0.5918 - val_accuracy: 0.6406\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.6654 - val_loss: 0.5914 - val_accuracy: 0.6406\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6637 - val_loss: 0.5909 - val_accuracy: 0.6406\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7030 - val_loss: 0.5904 - val_accuracy: 0.6458\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6716 - val_loss: 0.5900 - val_accuracy: 0.6458\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6665 - val_loss: 0.5895 - val_accuracy: 0.6510\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.6729 - val_loss: 0.5891 - val_accuracy: 0.6510\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.6802 - val_loss: 0.5886 - val_accuracy: 0.6510\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.6422 - val_loss: 0.5882 - val_accuracy: 0.6562\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.6620 - val_loss: 0.5877 - val_accuracy: 0.6562\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6660 - val_loss: 0.5873 - val_accuracy: 0.6562\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6653 - val_loss: 0.5868 - val_accuracy: 0.6562\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6459 - val_loss: 0.5864 - val_accuracy: 0.6562\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6603 - val_loss: 0.5859 - val_accuracy: 0.6562\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6545 - val_loss: 0.5855 - val_accuracy: 0.6562\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7041 - val_loss: 0.5850 - val_accuracy: 0.6562\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.6799 - val_loss: 0.5846 - val_accuracy: 0.6562\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6552 - val_loss: 0.5841 - val_accuracy: 0.6562\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.6758 - val_loss: 0.5837 - val_accuracy: 0.6615\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.6856 - val_loss: 0.5833 - val_accuracy: 0.6615\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.6935 - val_loss: 0.5828 - val_accuracy: 0.6615\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.6861 - val_loss: 0.5824 - val_accuracy: 0.6615\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.6732 - val_loss: 0.5820 - val_accuracy: 0.6719\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6566 - val_loss: 0.5815 - val_accuracy: 0.6719\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6320 - val_loss: 0.5811 - val_accuracy: 0.6771\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7075 - val_loss: 0.5807 - val_accuracy: 0.6771\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6630 - val_loss: 0.5802 - val_accuracy: 0.6771\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7080 - val_loss: 0.5798 - val_accuracy: 0.6771\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6864 - val_loss: 0.5794 - val_accuracy: 0.6771\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6752 - val_loss: 0.5790 - val_accuracy: 0.6771\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.6448 - val_loss: 0.5786 - val_accuracy: 0.6771\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6685 - val_loss: 0.5781 - val_accuracy: 0.6771\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.6845 - val_loss: 0.5777 - val_accuracy: 0.6823\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.6584 - val_loss: 0.5773 - val_accuracy: 0.6823\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6687 - val_loss: 0.5769 - val_accuracy: 0.6823\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.6870 - val_loss: 0.5765 - val_accuracy: 0.6823\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.6843 - val_loss: 0.5761 - val_accuracy: 0.6875\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6517 - val_loss: 0.5756 - val_accuracy: 0.6927\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.6761 - val_loss: 0.5752 - val_accuracy: 0.6927\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.6723 - val_loss: 0.5748 - val_accuracy: 0.6927\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6685 - val_loss: 0.5744 - val_accuracy: 0.6927\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.6671 - val_loss: 0.5740 - val_accuracy: 0.6927\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6651 - val_loss: 0.5736 - val_accuracy: 0.6927\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7168 - val_loss: 0.5732 - val_accuracy: 0.6927\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.6959 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7012 - val_loss: 0.5724 - val_accuracy: 0.6927\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7011 - val_loss: 0.5720 - val_accuracy: 0.6927\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.6752 - val_loss: 0.5716 - val_accuracy: 0.6979\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7044 - val_loss: 0.5712 - val_accuracy: 0.6979\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7037 - val_loss: 0.5708 - val_accuracy: 0.6979\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.6781 - val_loss: 0.5704 - val_accuracy: 0.6979\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6933 - val_loss: 0.5700 - val_accuracy: 0.6979\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.6910 - val_loss: 0.5696 - val_accuracy: 0.6979\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7065 - val_loss: 0.5693 - val_accuracy: 0.7031\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6854 - val_loss: 0.5689 - val_accuracy: 0.6979\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.6925 - val_loss: 0.5685 - val_accuracy: 0.6979\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6916 - val_loss: 0.5681 - val_accuracy: 0.6979\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.6820 - val_loss: 0.5677 - val_accuracy: 0.6979\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.6913 - val_loss: 0.5673 - val_accuracy: 0.6979\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.6933 - val_loss: 0.5670 - val_accuracy: 0.6979\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7245 - val_loss: 0.5666 - val_accuracy: 0.6979\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7063 - val_loss: 0.5662 - val_accuracy: 0.7031\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7314 - val_loss: 0.5658 - val_accuracy: 0.7083\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7009 - val_loss: 0.5654 - val_accuracy: 0.7083\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7226 - val_loss: 0.5651 - val_accuracy: 0.7083\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7101 - val_loss: 0.5647 - val_accuracy: 0.7083\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7160 - val_loss: 0.5643 - val_accuracy: 0.7083\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6968 - val_loss: 0.5640 - val_accuracy: 0.7135\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7092 - val_loss: 0.5636 - val_accuracy: 0.7135\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.6864 - val_loss: 0.5632 - val_accuracy: 0.7135\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7237 - val_loss: 0.5629 - val_accuracy: 0.7135\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7169 - val_loss: 0.5625 - val_accuracy: 0.7135\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7099 - val_loss: 0.5621 - val_accuracy: 0.7135\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.6981 - val_loss: 0.5618 - val_accuracy: 0.7135\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.6801 - val_loss: 0.5614 - val_accuracy: 0.7135\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7250 - val_loss: 0.5611 - val_accuracy: 0.7135\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7235 - val_loss: 0.5607 - val_accuracy: 0.7135\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7087 - val_loss: 0.5603 - val_accuracy: 0.7135\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7150 - val_loss: 0.5600 - val_accuracy: 0.7135\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7221 - val_loss: 0.5596 - val_accuracy: 0.7135\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7126 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7135 - val_loss: 0.5589 - val_accuracy: 0.7135\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7142 - val_loss: 0.5586 - val_accuracy: 0.7135\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.6990 - val_loss: 0.5582 - val_accuracy: 0.7135\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7328 - val_loss: 0.5579 - val_accuracy: 0.7135\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7260 - val_loss: 0.5575 - val_accuracy: 0.7135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VYtG3MqKsUP"
      },
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHaq6OTYKsUP",
        "outputId": "32d73c1d-6252-4f5a-ec77-80d2acd21919"
      },
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rmpn-QJKsUP",
        "outputId": "ed2a4a29-c024-4eec-c802-9a46143d5c59"
      },
      "source": [
        "y_pred_prob_nn_1[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41385788],\n",
              "       [0.46178812],\n",
              "       [0.30016127],\n",
              "       [0.33530262],\n",
              "       [0.298697  ],\n",
              "       [0.39449474],\n",
              "       [0.22669485],\n",
              "       [0.3640089 ],\n",
              "       [0.55994904],\n",
              "       [0.28681597]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "tVn04pwpKsUQ",
        "outputId": "6edc798f-2482-4fa0-b403-db3d1be160b3"
      },
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.714\n",
            "roc-auc is 0.817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU5dn/8e9FERRh6ShdXQgimoWAGB/Lxm7w0ajRn2DBPBpTNCpIVSCgAiIKYqKJayNoVsUajFijK4oiIK7SRGnCUpS2dNh2//6YgQzrltndmbmnfN6vFy+nnJ35zj3jXHOdc59zzDknAAAQP2r5DgAAAA5FcQYAIM5QnAEAiDMUZwAA4gzFGQCAOENxBgAgzlCckXLM7HAze93MtpvZi77zpCozm2pm9wYvn25my8L8u+vN7OPopvOrstdoZjlmdmMsMyG2KM5JzsxWm9leM9tlZhuDX4hHllrmVDN738x2BgvW62bWtdQyjczsITNbE3ysFcHrzct5XjOzW81skZntNrM8M3vRzE6M5usN068ltZLUzDl3RU0fzMwyzcyZ2aOlbv/YzK4PXr4+uMyQUsvkmVlmTTOEkTH0c/B96Ocg9Is+5LW8Wurvfxq8PafU7WZmK81sSU3yOec+cs79pCaPEY5UKOxIDhTn1PC/zrkjJWVI6i5p+IE7zOznkt6R9C9JrSUdI+lLSbPN7NjgModJ+o+kEyRdIKmRpJ9L2iLp5HKec4qk2yTdKqmppM6SXpPUp6rhzaxOVf+mEh0kfeOcK4pglt2SrjWzjhX8+VZJQ8ysYVWfN0IOfA56SOopaUQ5y22S9HMzaxZyW39J35Sx7BmSWko61sx6RTJsMovCZxpJhuKcQpxzGyW9rUCRPuB+SdOcc1Occzudc1udcyMkzZE0OrjMdZLaS7rUObfEOVfinPvBOXePc25m6ecxs06SbpbU1zn3vnNuv3Nuj3Pun865+4LLHLJarnRHE+zSbjazbyV9a2Z/M7MHSj3Pv8xsYPByazN72cw2mdkqM7u1rDEwszGSRkn6f8Eu8gYzq2VmI8zsOzP7wcymmVlacPmOwSw3mNkaSe+XM7z5kqZK+nM590vSUkmfShpYwTKhWdOCWTYFs40ws1rB+64PduYPmNm24Gu+MJzHdc6tk/SmpG7lLFKgwA+pq4LPVVvS/5P0zzKW7a/AD7uZwcsVvZ7uZrYguIbmBUn1Q+7LNLO8kOvDgmtndprZEjO79McPZ38Nrun52szODrkjzcyeNLMNZrbOzO41s9pmdrykvyvww2OXmeUHl68XHMc1wbUKfzezw4P3NTezf5tZvpltNbOPDrwHZbw+Z4G1RSvNbLOZTSz1fs02s8lmtkXS6Ire38peYxnP/X9mtjT4WXjbzDqUyvVHM/s2OJ73mNlxZvaJme0ws+nBH+CIIxTnFGJmbSVdKGl58PoRkk6VVNZ21+mSzg1ePkfSW865XWE+1dmS8pxzc2uWWL+S1FtSV0nPKVBQTZLMrImk8yQ9H/xCe12Bjr9N8PlvN7PzSz+gc+7PksZJesE5d6Rz7klJ1wf//ULSsZKOlPTXUn96pqTjJf3oMUOMlXS5mVW0enZkMFvTCpY54C+S0oKZzlTgR9JvQu7vLWmZpOYK/Mh68sD4VMTM2kn6paQvKlhsWvD5pMBrXiRpfanHOUKBTQT/DP67qrwv+eDtr0l6RoE1KS9KuryC518h6XQFXv8YSc+a2dEh9/cOLtNcgR9Er4SM6VRJRZLSFVhTdJ6kG51zSyX9XtKnwfe+cXD5+xRYs5MR/Js2CvyAk6Q7JOVJaqHAppA7JVV0zONLFVgr0UPSJZL+r1TmlcHHGavw3t/yXuNBZnZJMNdlwZwfKfD/S6jzJf1M0imShkjKknSNpHYK/EjrW8FrggcU59TwmpntlLRW0g/6b3fXVIHPwIYy/maDAl8KktSsnGXKU9XlyzM+2MnvVeALxynwhS0FisKnzrn1knpJauGcu9s5V+CcWynpcQU7vzBcLWmSc25l8AfIcAUKTeiqx9HOud3BLGUKrpn4u6S7K1gmV9K7koZWFCjYrV4laXhwjcZqSQ9KujZkse+cc48754ol/UPS0Qp88ZfntWC3+LGkDxX4kVJezk8kNQ3+0LhOgWJd2mWS9iuwWeQNSXVV/maLU4L3P+ScK3TOvSRpXgXP/6Jzbn1wLc0Lkr7VoZtQfgh5rBcU+JHSx8xaKfDD4/bg+/WDpMkq57MQ/DFzk6QBwc/aTgXG5cDyhQqMa4fgc33kKj4hwYTg46yR9JAOLXrrnXN/CW5OKVDl72+Zr7GM5/y9Av+vLA0+9jhJGaHds6T7nXM7nHOLFfih9U7w875dgbUo3St4TfCA4pwafuWcaygpU1IX/bfobpNUosCXT2lHS9ocvLylnGXKU9Xly7P2wIXgF+Lz+u+XXT/9dzVrB0mtg6se84MF6E5VXKhCtZb0Xcj17yTVKfX3axWeCZLON7OfVrDMKEl/CBaS8jRXoJiVztUm5PrGAxecc3uCFw+Z7FfKr5xzjZ1zHZxzf6zoh0bQM5JuUWCNwqtl3N9f0nTnXJFzbp+kl1X+qu3WktaVKmzflbOszOw6M8sNeT+76b+fW5XzWK0V+CzUlbQh5G8fU2C7eFlaSDpC0uchy78VvF2SJiqwpumd4OrqYeVlDgr9nBzIVNZ94by/5b3G0jpImhKSf6skK/VY34dc3lvG9Yo+N/CA4pxCnHMfKrDK74Hg9d0KbAMta8bylQpMApOk9xQoOA3CfKr/SGprZj0rWGa3Al+KBxxVVuRS15+T9OtgR9BbgWIgBb70VgULz4F/DZ1zvwwz73oFvuAOaK/AatHQL7CwTt/mnNuiQMd0TwXLfC3pFUl3VfBQmxXo2krnWhdOjgh5RtIfJc0MKf6SDm4iOUvSNRbYC2CjAmszfmllz+DfIKlNqdXu7ct60uD7+7gCPwyaBVc/L1Kg4BxQ1mOtV+CzsF9S85DPQiPn3AnB5Uq/j5sVKE4nhCyfFpw4p2BXe4dz7lhJF0saWNG2XwVWE5fOdEDoc4fz/pb3GktbK+l3pT7/hwfXfiBBUZxTz0OSzg3p7IZJ6h+cyNLQzJpYYN/TnyuwrU8KfEmvlfSymXWxwASqZmZ2p5n9qAA6576V9Kik5yww0ecwM6tvZleFdB65ki4zsyPMLF3SDZUFd859ocCX2hOS3nbO5Qfvmitpp5kNtcA+zLXNrJuFP3v4OUkDzOwYC+xedGCbdJVncwdNUmBb/vEVLDNGge2Ljcu6M7iqerqkscH3pYMCE8merWamKnPOrVJgW2hZPyKuVWD29k8U2FabocB22zyVvf3yUwV+8NxqZnXN7DKVP9O/gQKFbJMkmdlv9OPJay1DHusKBcZ6pnNugwKr2R+0wO5/tYKTn84M/t33CvxwPCz4GksU+CEw2cxaBp+vzYH5CmZ2kZmlB4vkdknFCqxtKs/g4P9D7RTYW+GFshYK8/0t8zWW8XB/lzTczE4IZk4LLo8ERnFOMc65TQpsPxwVvP6xApNFLlOgu/lOge1PpwWLrJxz+xWYFPa1AttLdyhQEJtL+qycp7pVgUlVjygwk3mFApNlXg/eP1mB7W7fK7C9tKyZwGXJDmbJDnlNxZIuUqBArNJ/C3hamI/5lAI/QGYF/36fpD+F+bc/4pzbocAErXInfQUL3zMKFKLy/EmBNQwrFdhOnB3MGjPOuY+D2/VL6y/pUefcxtB/ChSKH63ads4VKPAZu16B1a7/T4G1B2U95xIFtr9+qsDn40RJs0st9pmkTgq812Ml/Tq41kIKbCM/TNISBTbdvKT/bmZ5X9JiSRvN7MBmm6EKrLqeY2Y7FFhTdGBSX6fg9V3BPI865z4oK3fQvyR9rsCPzzckPVnBspW9vxW9xoOcc68qsDnl+WD+RQpM/EQCs4rnNgAAwmFmTlIn59xy31mQ+OicAQCIMxRnAADiDKu1AQCIM3TOAADEGYozAABxptIzo5jZUwrspvKDc+5HB8oP7v83RYFD5u2RdL1zbkFlj9u8eXPXsWPHg9d3796tBg3CPcYFqorxjS7GN3oY2+hifKOn9Nh+/vnnm51zLSr4k4PCOW3ZVAX2Vy3r2LpSYH+6TsF/vSX9LfjfCnXs2FHz588/eD0nJ0eZmZlhxEF1ML7RxfhGD2MbXYxv9JQeWzMr95C1pVW6Wts5N0uBgwaU5xIFTjnonHNzJDUudfYYAABQBZE44XcbHXpA97zgbZE4KxEAAAnn9ttvV15eXrXXSkSiOIfNzG5S4PRsatWqlXJycg7et2vXrkOuI7IY3+hifKOHsY0uxjfySkpK9Pzzz6tJkybVHttIFOd1OvRMLG1VzplznHNZCpzkWz179nShvyjY7hFdjG90Mb7Rw9hGF+MbWSUlJVq6dKnat2+vgoKCao9tJHalmiHpOgs4RdL24JlhAABIGc45DR8+XM45HXHEEZX/QQXC2ZXqOUmZkpqbWZ6kPytwknA55/6uwCnMfqnAWV32KHAaPAAAUkZhYaFmz56tYcOGqUmTJjV+vEqLs3OurHOzht7vJN1c4yQAACSoe+65R9ddd11ECrMU4wlhAIDkkZWVpezs7MoXTGIlJSXatGmTWrZsqVmzZh28PTc3V6EH2qoqDt8JAKiW7Oxs5ebm+o7h1fr165WWlqbAwTL/KyMjQ2effXa1H5fOGQBQbRkZGSm5K9bu3bv12GOPaeDAgeUuU5NxoXMGAKCKXnvtNfXr1y9qj09xBgAgTNu3b9fQoUPVr18/HXXUUVF7HoozAABhKCgo0Ny5czV06NAfbWOONIozAACV2Lx5swYMGKAzzzxTTZs2jfrzMSEMAJJAdXdrys/PV+PGjav1nLm5ucrIyKjW3yaSLVu26LvvvtP48eN12GGHxeQ56ZwBIAn42K0pIyMjqpOi4sGGDRs0atQodenSRY0aNYrZ89I5A0CSqM5uTZz4onx5eXnatm2bJk6cWONjZVcVnTMAAKVs2LBB999/vzp16hTzwizROQMAcIgVK1Zo586dmjhxourVq+clA50zAABBO3bs0N/+9jedcMIJ3gqzROcMADER7ZNEpMrM6WhasmSJvv/+e02cODHq+zFXhs4ZAGIg2rOpU2HmdDQVFRXp5Zdf1hlnnOG9MEt0zgAQM6l6koh4t2DBAq1cuVIjR470HeUgOmcAQMpyzmnevHm6/PLLfUc5BJ0zACAlzZ49W4sWLdLvfvc731F+hM4ZAJBydu/erW3btummm27yHaVMdM4AEAWlZ2czmzp+vPfee1q8eLFuu+0231HKRecMAFFQenY2s6njw6pVq9SsWbO4LswSnTMARA2zs+PLv//9b61Zs0Z//OMffUepFMUZAJD0Pv74Y/Xq1UsXXXSR7yhhYbU2ACCpzZw5U8uXL1erVq18RwkbnTMAIGm98sorOu+883TkkUf6jlIlFGcAERGtY0fn5+ercePGEX/caGN2tn+zZs1SQUFBwhVmidXaACIk2seOTjTMzvbrySefVLdu3XTVVVf5jlItdM4AIiYas5NzcnKUmZkZ0cdEclu0aJGaN2+upk2b+o5SbXTOAICkMWXKFB1xxBG65JJLfEepEYozACAprF27Vl27dtWxxx7rO0qNUZwBAAnNOaf77rtPmzdv1rnnnus7TkRQnAEACcs5p7y8PP3iF79Q9+7dfceJGIozACAhOec0ZswYbdy4Ub179/YdJ6KYrQ0ASDglJSVavHixrrnmGqWnp/uOE3F0zgCAhOKc04gRI1RSUpKUhVmicwYAJJCioiLl5ORo6NChSktL8x0nauicAQAJY9y4cWrXrl1SF2aJzhlAJcI9ZjbHkkY0FRQU6IUXXtCIESNUq1by95XJ/woB1Ei4x8zmWNKIpscff1ynn356ShRmic4ZQBiiccxsIBx79+7VX//6Vw0ePNh3lJhKjZ8gAICE45zT66+/rquvvtp3lJijOAMA4s7OnTs1ePBg/frXv1br1q19x4k5ijMAIK7s27dPn3/+uYYNG5Yy25hLS81XDQCIS1u3btXAgQN1yimnqHnz5r7jeMOEMACHKL3rFLtIIVa2bNmiNWvWaPz48apfv77vOF7ROQM4ROldp9hFCrHw/fffa9SoUUpPT0/6A4yEg84ZwI+w6xRiaf369dq8ebPuv/9+NWjQwHecuEDnDADwZtOmTbrvvvvUqVMnCnMIOmcAgBerV6/Wli1bNHHiRNWrV893nLhC5wwAiLk9e/boL3/5i0488UQKcxnonIEUVNHJLJidjWhbtmyZVq9erQceeEBm5jtOXKJzBlJQRSezYHY2oqm4uFgvvfSSzj77bApzBeicgRTFjGzE2pdffqlFixbprrvu8h0l7tE5AwCirqSkRPPmzVPfvn19R0kIdM4AgKiaM2eO5s2bpz/96U++oyQMOmcAQNTs3LlT27Zt0y233OI7SkKhcwYAREVOTo7mz5+vQYMG+Y6ScOicAQARt3z5cjVt2pTCXE0UZwBARL311luaOXOmTjrpJN9REhartQEAETNr1iz16NFDF1xwge8oCY3OGQAQEe+8846WLVumli1b+o6S8OicAQA19sorr+icc87Reeed5ztKUqA4A0mK42cjVj777DPt3btXjRo18h0labBaG0hSHD8bsfD000+rY8eOuvrqq31HSSp0zkAS4/jZiKZvv/1WjRo1UqtWrXxHSTp0zgCAKnvkkUdUXFysyy+/3HeUpERxBgBUycaNG5Wenq4uXbr4jpK0KM4AgLA45/TAAw9ozZo1Ov/8833HSWpsc0bSqmi2cqTl5+ercePGMXmucDEjG5HknNO6det02mmn6eSTT/YdJ+nROSNpVTRbORUwIxuR4pzTvffeq7Vr1+qUU07xHScl0DkjqcVqtnJOTo4yMzOj/jxArDnntHDhQvXr10/HHXec7zgpg84ZAFCu0aNHq6ioiMIcY3TOAIAfKS4u1nvvvadBgwapYcOGvuOkHDpnAMCP3H///WrXrh2F2RM6ZwDAQYWFhXr22Wc1dOhQ1apF/+YLxRkRE8tdl8LBrkRA1U2dOlVnnXUWhdkzRh8RE2+7LrErERC+ffv2aezYsbrxxhuZ/BUHwuqczewCSVMk1Zb0hHPuvlL3t5f0D0mNg8sMc87NjHBWJABOtAAkHuec3nzzTfXv319m5jsOFEbnbGa1JT0i6UJJXSX1NbOupRYbIWm6c667pKskPRrpoACAyNu7d68GDhyo//3f/1Xbtm19x0FQOKu1T5a03Dm30jlXIOl5SZeUWsZJOnCW7TRJ6yMXEQAQDXv37tXy5cs1fPhw1anDFKR4Es670UbS2pDreZJ6l1pmtKR3zOxPkhpIOqesBzKzmyTdJEmtWrU6ZPXnrl27WB0aRbEY3/z8fElKyfeRz2/0MLbRsWvXLj3++OO65pprtGTJEi1ZssR3pKRTk89upH4q9ZU01Tn3oJn9XNIzZtbNOVcSupBzLktSliT17NnThR7ukMMfRlcsxvfAiR9S8X3k8xs9jG3kbd26VWvXrtXUqVP15ZdfMr5RUpPPbjirtddJahdyvW3wtlA3SJouSc65TyXVl9S8WokAAFGzefNmjRw5Uh07dlSTJk18x0E5winO8yR1MrNjzOwwBSZ8zSi1zBpJZ0uSmR2vQHHeFMmgAICa2bhxo9atW6f77rtPaWlpvuOgApUWZ+dckaRbJL0taakCs7IXm9ndZnZxcLE7JP3WzL6U9Jyk651zLlqhAQBVs23bNt1zzz1KT0/nkJwJIKxtzsF9lmeWum1UyOUlkv4nstEAAJGwZs0arV+/XpMmTVK9evV8x0EYOEIYACSx/fv3a8qUKerevTuFOYGwYxtqJPR42hzLGogv3377rZYtW6YHHniAI38lGDpn1Ejo8bQ5ljUQP5xzeumll3TBBRdQmBMQnTNqjONpA/Fl0aJFmj9/voYPH+47CqqJzhkAkkhJSYnmz5+v6667zncU1ACdMwAkifnz52vWrFkaOHCg7yioITpnAEgC27dv19atWzVgwADfURABdM6oktDZ2RIztIF48NFHH2n27NkaNmyY7yiIEDpnVEno7GyJGdqAb8uWLVPTpk01dOhQ31EQQXTOqDJmZwPx4b333tNXX33FNuYkRHEGgAQ0a9YsnXTSSTrnnHN8R0EUsFobABJMTk6OlixZopYtW/qOgiihcwaABPLqq68qMzNTmZmZvqMgiijOkPTjWdjlYXY24E9ubq527NihJk2a+I6CKGO1NiT9eBZ2eZidDfjxzDPPqFmzZurfv7/vKIgBOmccxCxsID6tWbNG9erVU7t27XxHQYzQOQNAHHvssce0bds2XXnllb6jIIYozgAQpzZt2qT27dvrpz/9qe8oiDGKMwDEocmTJ2vZsmW68MILfUeBB2xzBoA44pzTunXrdOqpp6p3796+48ATOmcAiBPOOY0fP16rVq2iMKc4OmcAiAPOOeXm5qpv37465phjfMeBZ3TOABAH7r33XhUVFVGYIYnOGQC8Kikp0cyZMzVw4EA1aNDAdxzECTpnAPBo0qRJ6tChA4UZh6BzBgAPioqK9PTTT+uOO+6QmfmOgzhD5wwAHjz77LM688wzKcwoE50zAMTQ/v37NWHCBI0cOZLCjHLROQNAjDjn9N5776l///4UZlSI4gwAMbBnzx4NGDBA5557rjp06OA7DuIcxRkAomzv3r1auHChhg0bpsMOO8x3HCQAijMARNGOHTs0aNAgdenSRUcddZTvOEgQTAhLUVlZWcrOzj54PTc3VxkZGR4TAcln27ZtWrNmje6++26lpaX5joMEQuecorKzs5Wbm3vwekZGhvr16+cxEZBctm7dqhEjRqhDhw5q1qyZ7zhIMHTOKSwjI0M5OTm+YwBJZ9OmTVq3bp3Gjx+vRo0a+Y6DBETnDAARtHPnTo0ZM0bp6ekUZlQbnTMARMi6deu0atUqTZo0iVnZqBE6ZwCIgKKiIk2ZMkU9e/akMKPG6JyTWOiM7Pz8fDVu3PjgfczOBiJn5cqV+vLLL3X//ff7joIkQeecxErPyA7F7GwgMpxzevnll3XRRRf5joIkQuec5A7MyM7JyVFmZqbvOEBSWbp0qT766CMNHjzYdxQkGTpnAKiG4uJiff7557rhhht8R0ESonMGgCr64osv9M4772jo0KG+oyBJ0TkDQBVs27ZN27ZtY1U2oorOOYlwvGwguj755BO9//77GjFihO8oSHJ0zkmE42UD0bN06VI1adJEd911l+8oSAF0zkmG42UDkffhhx9q7ty5GjRokMzMdxykAIozAFTgww8/VJcuXXTmmWf6joIUwmptACjHJ598ooULF6pVq1a+oyDF0DkDQBn+9a9/6dRTT9Wpp57qOwpSEMU5AZSehV0eZmcDkbFkyRJt3rxZLVq08B0FKYrV2gmgomNkh2J2NlBz//znP1WvXj2O/AWv6JwTBLOwgejbuHGjatWqpeOOO853FKQ4OmcAkPTEE09o7dq16tu3r+8oAMUZALZu3aqjjz5avXr18h0FkMRqbQAp7uGHH9aJJ56oPn36+I4CHERxjgOVzcZmFjYQHXl5eerdu7d69+7tOwpwCFZrx4HKZmMzCxuIvPvuu0/ffvsthRlxic45TjAbG4gN55w+//xz9evXT+3bt/cdBygTnTOAlDJhwgQVFhZSmBHX6JwBpISSkhK9/vrruu2223T44Yf7jgNUiM4ZQEp45JFH1KFDBwozEgKdM4CkVlxcrMcff1y33HIL52JGwqBzBpDUXnjhBWVmZlKYkVDonAEkpYKCAo0bN06jRo1SrVr0IUgsfGIBJJ2SkhJ9+OGH6t+/P4UZCYlPLYCksnfvXg0YMECnnXaajjnmGN9xgGphtTaApLFnzx4tXbpUQ4YMYVY2EhqdM4CksHPnTg0ePFgdO3ZUmzZtfMcBaoTi7ElWVpYyMzOVmZlZ4XG1AVRu+/btWrlypUaPHq1mzZr5jgPUGMXZk9CTXXBiC6D68vPzNXz4cLVr104tWrTwHQeICLY5e8TJLoCa2bx5s9asWaPx48crLS3NdxwgYuicASSkvXv3avTo0erUqROFGUmHzhlAwtmwYYOWLl2qyZMnq27dur7jABFH5wwgoZSUlOihhx7SKaecQmFG0qJzBpAwVq9erTlz5mjChAm+owBRFVbnbGYXmNkyM1tuZsPKWeZKM1tiZovNLDuyMQFAeuWVV3TZZZf5jgFEXaWds5nVlvSIpHMl5UmaZ2YznHNLQpbpJGm4pP9xzm0zs5bRCgwg9SxbtkzvvvuuBg4c6DsKEBPhdM4nS1runFvpnCuQ9LykS0ot81tJjzjntkmSc+6HyMYEkKqKi4u1YMEC/f73v/cdBYiZcIpzG0lrQ67nBW8L1VlSZzObbWZzzOyCSAUEkLq++uorZWdnq2/fvqpThykySB2R+rTXkdRJUqaktpJmmdmJzrn80IXM7CZJN0lSq1atDjkAx65du1LqgBz5+YGhidVrTrXxjTXGN/K2b9+uVatW6ZJLLmFso4jPbvTUZGzDKc7rJLULud42eFuoPEmfOecKJa0ys28UKNbzQhdyzmVJypKknj17uszMzIP35eTkKPR6smvcuLEkxew1p9r4xhrjG1lz587VBx98oDFjxjC2Ucb4Rk9Nxjac1drzJHUys2PM7DBJV0maUWqZ1xTommVmzRVYzb2yWokApLTFixcrLS1No0eP9h0F8KbS4uycK5J0i6S3JS2VNN05t9jM7jazi4OLvS1pi5ktkfSBpMHOuS3RCg0gOc2ePVszZsxQ586dZWa+4wDehLXN2Tk3U9LMUreNCrnsJA0M/gOAKps1a5Y6d+6sU089lcKMlMfhOwF4N3/+fC1YsEBHHXUUhRkQxRmAZ6+//rpat26t22+/3XcUIG6w42CMZGVlKTv7v0c1zc3NVUZGhsdEgH8rVqzQhg0b1Lp1a99RgLhC5xwj2dnZys3NPXg9IyND/fr185gI8OuFF17Q/v37ddNNN/mOAsQdOucYysjIYGd/QNKWLVtUVFSkrl27+o4CxCWKM4CYmjp1qtLT03X11TlJw70AABxjSURBVFf7jgLELVZrA4iZ7du3q0WLFjrttNN8RwHiGp0zgJh49NFHlZ6erj59+viOAsQ9ijOAqFu7dq169eqlXr16+Y4CJASKcwSV3l0qFLtOIVU9+OCDOumkk3Tuuef6jgIkDLY5R1Dp3aVCsesUUo1zTp999pmuuuoqCjNQRXTOEcbuUkDApEmTdMopp6hNmza+owAJh+IMIKKcc3r11Vd18803q379+r7jAAmJ1doAIiorK0sdOnSgMAM1QOcMICKKi4v16KOP6pZbbuHMUkANUZzDUNEs7FDMyEYqe+WVV3TWWWdRmIEIYLV2GCqahR2KGdlIRYWFhRo5cqQuvfRSnXDCCb7jAEmBzjlMzMIGfqykpESzZ89W//79VacOXydApNA5A6iWffv2acCAAfrZz36m9PR033GApMJPXQBVtnfvXi1btkyDBg1Sw4YNfccBkg6dM4Aq2b17twYPHqzWrVurXbt2vuMASYnOGUDYdu7cqVWrVmnkyJFq2bKl7zhA0qJzBhCWnTt3atiwYWrdurVatWrlOw6Q1OicAVRq69atWrlypcaNG6e0tDTfcYCkR+cMoEIFBQUaNWqUOnXqRGEGYoTOGUC5vv/+e+Xm5uqhhx5iP2YghuicAZTJOaeHH35Yp512GoUZiDH+jwPwI2vXrlVOTo7Gjh3rOwqQkuicAfzIa6+9piuuuMJ3DCBl0TkDOGjFihWaMWOGBgwY4DsKkNLonAFICpxdasGCBbrlllt8RwFSHp0zAC1evFjTp0/XmDFjfEcBIDpnIOX98MMPys/P16hRo3xHARBEcQZS2Oeff66HH35Yp556qmrXru07DoAgijOQohYtWqSGDRvqnnvukZn5jgMgBMUZSEFz587Va6+9pk6dOlGYgThEcQZSzEcffaS2bdvqrrvuojADcYriDKSQr776SnPnzlXr1q0pzEAcozgDKWLmzJlKS0vTHXfc4TsKgEpQnIEUsHbtWq1evVodOnTwHQVAGCjOQJJ76aWXtGXLFv3xj3/0HQVAmCjOQBLbvn279u7dq4yMDN9RAFQBh+8EktQzzzyjNm3a6Nprr/UdBUAV0TkDSWjHjh1q1qyZzjrrLN9RAFQDnTOQZB577DG1bdtWffr08R0FQDVRnIEk8t1336lnz5762c9+5jsKgBqgOJchKytL2dnZB6/n5uYyoQZxb8qUKercubMuvPBC31EA1BDFuQzZ2dmHFOSMjAz169fPcyqgbM45ffLJJ7ryyit19NFH+44DIAIozuXIyMhQTk6O7xhApR5++GFlZGRQmIEkQnEGEpRzTi+++KJ+//vfq169er7jAIggdqUCEtTTTz+tDh06UJiBJETnDCSYkpISPfzww7rttts4sxSQpCjOYnY2Esu///1vnXXWWRRmIImxWlv/nZ19ALOzEY+Kioo0cuRInX/++TrppJN8xwEQRXTOQczORjwrLi7W3Llzde2117KNGUgBdM5AnCsoKNCgQYN0/PHHq3Pnzr7jAIgBOmcgju3bt0/ffPONbr/9djVp0sR3HAAxQucMxKk9e/Zo8ODBatGihTp06OA7DoAYStninJWVpczMTGVmZh4yGQyIB7t379by5ct15513cuQvIAWlbHEOnaHN7GzEk927d2vIkCE66qijKMxAikrpbc7M0Ea8yc/P17JlyzRu3DilpaX5jgPAk5TtnIF4U1RUpFGjRqlz584UZiDFpXTnDMSLTZs26bPPPtPkyZNVu3Zt33EAeEbnDHjmnNNf//pXZWZmUpgBSEqhzpnjZyMerVu3Tm+//bbGjBnjOwqAOJIynTPHz0a8cc5pxowZ6tu3r+8oAOJMynTOErOzET9WrVqlF154QcOGDfMdBUAcSpnOGYgX+/fvV25urgYOHOg7CoA4RXEGYmjp0qUaM2aMLr30Uh122GG+4wCIUxRnIEY2btyo7du365577vEdBUCcozgDMZCbm6spU6bo5JNPZncpAJWiOANRtmjRIjVo0EBjx45VrVr8LwegcnxTAFG0YMECvfTSS0pPT6cwAwgb3xZAlMyePVvNmzfXn//8Z5mZ7zgAEgjFGYiCr7/+Wh9//LHatWtHYQZQZRRnIMLeeecd1apVS0OHDqUwA6iWsIqzmV1gZsvMbLmZlXtIIzO73MycmfWMXEQgcXz//ff6+uuv1blzZ99RACSwSouzmdWW9IikCyV1ldTXzLqWsVxDSbdJ+izSIasrKytLmZmZyszMPOS42kA0vPbaa1q9erVuvfVW31EAJLhwOueTJS13zq10zhVIel7SJWUsd4+kCZL2RTBfjYSe7IITXSCa9u7dqx07dqh3796+owBIAuGc+KKNpLUh1/MkHfINZGY9JLVzzr1hZoMjmK/GONkFou25557T2rVrNWTIEN9RACSJGp+VysxqSZok6fowlr1J0k2S1KpVq0OK5q5duyJeRPPz8yWJ4qzojC+k3bt367vvvlO3bt0Y3yjhsxtdjG/01GRswynO6yS1C7neNnjbAQ0ldZOUE5yZepSkGWZ2sXNufugDOeeyJGVJUs+ePV1mZubB+3JychR6PRIaN24sSRF/3EQUjfFNdU899ZSaNm2qYcOGMb5RxNhGF+MbPTUZ23CK8zxJnczsGAWK8lWSDm68dc5tl9T8wHUzy5E0qHRhBpLJypUr1aNHD2VkZPiOAiAJVTohzDlXJOkWSW9LWippunNusZndbWYXRzsgEG8eeeQRLV68mMIMIGrC2ubsnJspaWap20aVs2xmzWMB8emjjz7SFVdcoZYtW/qOAiCJcYQwIEx/+9vfVFhYSGEGEHU1nq0NJDvnnJ5//nndeOONqlu3ru84AFIAnTNQiezsbHXs2JHCDCBm6JyBcpSUlOihhx7Sbbfdptq1a/uOAyCFJFVxzsrKUnZ29sHrubm5zKhFtb3zzjv6xS9+QWEGEHNJtVo79FjaEsfTRvUUFxdrxIgROuOMM9S9e3ffcQCkoKTqnCWOpY2aKS4u1oIFC3T11VfriCOO8B0HQIpKqs4ZqInCwkINHjxYHTp00PHHH+87DoAUlnSdM1Ad+/fv17fffqtbbrmF/ZgBeEfnjJS3b98+DR48WI0bN9axxx7rOw4AJF7nXHpGdihmZ6Oq9uzZo+XLl2vYsGFq3bq17zgAICkBO+fSM7JDMTsbVbFv3z4NGTJELVu2pDADiCsJ1zlLzMhGze3YsUMLFy7UuHHj1KhRI99xAOAQCdc5AzVVUlKikSNHqkuXLhRmAHEpITtnoLq2bNmiWbNmafLkyapVi9+mAOIT305IKY8++qjOPvtsCjOAuEbnjJSwceNG/etf/9LIkSN9RwGAStE+IOk55/T666/r2muv9R0FAMJC54yk9t1332natGl0zAASCp0zkta+ffv01VdfaciQIb6jAECVUJyRlL755huNGjVKF110kerVq+c7DgBUCcUZSWf9+vXavn27xo0bJzPzHQcAqozijKSycOFCTZkyRT169FCdOkypAJCY+PZC0li0aJHq16+v8ePHsx8zgITGNxiSwqJFizR9+nQdd9xxFGYACY9vMSS8Tz/9VA0aNNCYMWMozACSAt9kSGgrV67UBx98oI4dOzL5C0DSoDgjYf3nP//Rnj17NHz4cAozgKRCcUZC2rp1qxYtWqRu3bpRmAEkHWZrI+H8+9//Vlpamm677TbfUQAgKuickVD27dunrVu36vTTT/cdBQCihs4ZCWP69OmqX7++rrvuOt9RACCqKM5ICDt27FCjRo10wQUX+I4CAFFHcUbc+8c//qEjjjhCV1xxhe8oABATFGfEtW+//VY9evTQiSee6DsKAMQME8IQtx577DEtWbKEwgwg5dA5Iy598MEHuvzyy9W8eXPfUQAg5uicEXeeeOIJFRYWUpgBpCw6Z8QN55yeffZZXX/99ZyLGUBKo3NG3HjppZfUsWNHCjOAlMe3ILxzzmnSpEm69dZbVbduXd9xAMA7Omd498EHH+jMM8+kMANAEMUZ3pSUlGjEiBHq2bOnevbs6TsOAMQNVmvDi+LiYi1cuFBXXXWVGjVq5DsOAMQVOmfEXGFhoYYOHaoWLVqoW7duvuMAQNyhc0ZMFRQUaPny5frd736nNm3a+I4DAHGJzhkxs3//fg0ZMkRHHHGEOnXq5DsOAMQtOmfExN69e/XNN99o8ODBdMwAUAk6Z0RdYWGhBg8erObNm1OYASAMdM6Iqp07d2rBggUaP368GjZs6DsOACQEOmdEjXNOo0ePVteuXSnMAFAFdM6Iim3btundd9/VxIkTVasWvwEBoCr41kRUZGVl6bzzzqMwA0A10Dkjon744QdNnz5dQ4cO9R0FABIWbQ0ixjmnN954Q7/5zW98RwGAhEbnjIjIy8tTVlaW7r77bt9RACDh0Tmjxvbu3atFixbpzjvv9B0FAJICxRk1smLFCt111106//zzVb9+fd9xACApUJxRbXl5edq+fbsmTJggM/MdBwCSBsUZ1bJ06VI9/PDDOumkk1S3bl3fcQAgqVCcUWWLFy9WnTp1NH78eNWpw5xCAIg0ijOq5Ouvv1Z2draOO+441a5d23ccAEhKFGeEbe7cuapdu7buvfdejvwFAFHENyzCkpeXp7feekvp6elM/gKAKGODISr14YcfqmHDhho5ciSFGQBigM4ZFdq5c6e++OILde/encIMADGSEJ1zVlaWsrOzJUm5ubnKyMjwnCg1vPnmm6pbt65uv/1231EAIKUkROecnZ2t3NxcSVJGRob69evnOVHyKygo0KZNm3TOOef4jgIAKSchOmcpUJRzcnJ8x0gJr7zyikpKSnTdddf5jgIAKSlhijNiY/v27TryyCN13nnn+Y4CACmL4oyDnn32WdWqVYvNBgDgGcUZkgJH/urRo4e6du3qOwoApLy4LM6hs7MlZmhH25NPPqnGjRvr8ssv9x0FAKA4Lc4HZmcfKMjM0I6e//znP7r00kvVtGlT31EAAEFxWZwlZmfHwrRp09S8eXMKMwDEmbgtzoiuadOmqV+/fpzyEQDiUEIchASRNWPGDLVv357CDABxKqzibGYXmNkyM1tuZsPKuH+gmS0xs6/M7D9m1iHyUVFTzjk9+OCDOv/885WZmek7DgCgHJUWZzOrLekRSRdK6iqpr5mV3t/mC0k9nXMnSXpJ0v2RDoqamz17tk477TTVq1fPdxQAQAXC6ZxPlrTcObfSOVcg6XlJl4Qu4Jz7wDm3J3h1jqS2kY2JmigpKdFTTz2l448/Xr179/YdBwBQiXA2OraRtDbkep6kir7hb5D0Zll3mNlNkm6SpFatWh0yG3vXrl0Hr+fn50sSs7UjoLi4WGvWrFGvXr20cOFC33GSVujnF5HF2EYX4xs9NRnbiM4IMrNrJPWUdGZZ9zvnsiRlSVLPnj1d6HbPnJycg9tBGzduLElsF62hoqIi3Xnnnbr55pu1atUqxjOKQj+/iCzGNroY3+ipydiGs1p7naR2IdfbBm87hJmdI+kuSRc75/ZXKw0iprCwUMuXL9cNN9ygDh2YnwcAiSSc4jxPUiczO8bMDpN0laQZoQuYWXdJjylQmH+IfExURUFBgYYMGaK6devqJz/5ie84AIAqqnS1tnOuyMxukfS2pNqSnnLOLTazuyXNd87NkDRR0pGSXjQzSVrjnLs4irlRjn379unrr7/WoEGD1KZNG99xAADVENY2Z+fcTEkzS902KuTyORHOhWooLi7WkCFDNHjwYAozACQwDhGVJHbv3q05c+Zo/PjxatCgge84AIAa4PCdSeLuu+9Wt27dKMwAkATonBNcfn6+3njjDd13330Kbu8HACQ4OucE9+STT+rCCy+kMANAEqFzTlCbN2/WtGnTdMcdd/iOAgCIMDrnBOSc01tvvaXf/va3vqMAAKKA4pxg1q9frzvvvFPXXHONGjZs6DsOACAKKM4JZPfu3VqyZIlGjRpV+cIAgIRFcU4Qq1ev1p133qmzzjpLhx9+uO84AIAoojgngLy8POXn52vixImqVYu3DACSHd/0ce6bb77R5MmTdcIJJ+iwww7zHQcAEANxsStVVlaWHn300YPncc7NzVVGRobnVP4tWbJEderU0YQJE1SnTly8VQCAGIiLzjk7O1vLly8/eD0jI0P9+vXzmMi/FStWaNq0aTruuOMozACQYuLmWz89PV05OTm+Y8SFzz//XIcffrjGjRvHNmYASEF888eZH374Qa+//rqOP/54CjMApKi46Zwhffzxx6pTp45Gjx7tOwoAwCNaszixd+9ezZs3T7179/YdBQDgGZ1zHHj33XdVUFCgAQMG+I4CAIgDdM6eFRYW6vvvv1efPn18RwEAxAk6Z49mzJihXbt26ZprrvEdBQAQRyjOnmzbtk0NGjTQxRdf7DsKACDOUJw9eP7551VQUKDrrrvOdxQAQByiOMfY4sWL1b17d/3kJz/xHQUAEKeYEBZD06ZN0+LFiynMAIAK0TnHyDvvvKNLLrlEaWlpvqMAAOIcnXMMPP/889q/fz+FGQAQFjrnKJs6daquvvpq1a1b13cUAECCoHOOorfeektt27alMAMAqoTOOQqcc3rwwQf1hz/8QQ0aNPAdBwCQYOicI8w5p3nz5unnP/85hRkAUC0U5wgqKSnRn//8Z7Vv317/8z//4zsOACBBUZwjpKSkRN98841+9atf6aijjvIdBwCQwCjOEVBcXKzhw4erTp066tGjh+84AIAEx4SwGioqKtKKFSv0m9/8Runp6b7jAACSAJ1zDRQWFmrIkCEyM3Xp0sV3HABAkqBzrqb9+/dr8eLFuuOOO9SmTRvfcQAASYTOuRpKSko0dOhQNWvWjMIMAIg4Oucq2rNnj2bNmqXx48fr8MMP9x0HAJCE6JyraOzYsfrpT39KYQYARA2dc5h27NihV199Vffee6/MzHccAEASo3MO09NPP60+ffpQmAEAUUfnXImtW7fqiSee0JAhQ3xHAQCkCDrnCpSUlOjdd9/V7373O99RAAAphOJcjo0bN2ro0KG68sorlZaW5jsOACCFUJzLsHPnTn399dcaPXo025gBADFHcS5lzZo1uvPOO3XaaadxPmYAgBcU5xBr165Vfn6+HnjgAdWpw1w5AIAfFOegFStWaPLkyerSpYvq1avnOw4AIIXRHkr6+uuvJUkTJkxQ3bp1PacBAKS6lO+c16xZo6efflqdOnWiMAMA4kJKd865ubmqVauWxo8fr1q1Uv53CgAgTqRsRcrPz9err76qbt26UZgBAHElJTvnOXPmqKCgQGPGjPEdBQCAH0m5lrGgoECffvqpTj/9dN9RAAAoU0p1zu+//77y8/M1YMAA31EAAChXynTOhYWF2rBhgy677DLfUQAAqFBKdM5vvPGGNm3apOuvv953FAAAKpX0xXnz5s1q0KCB+vTp4zsKAABhSeri/OKLL2rnzp36v//7P99RAAAIW9IW56+++krdu3dXenq67ygAAFRJUk4Ie+6557Rw4UIKMwAgISVd5/zmm2+qT58+atSoke8oAABUS1IV55dfflm1atWiMAMAElrSFOepU6eqb9++nIsZAJDwkmKb8/vvv6+jjjqKwgwASAoJ3Tk75zRp0iTdeOONSktL8x0HAICISNjO2Tmnr776Sr169aIwAwCSSkIWZ+ec7rnnHjVp0kRnnHGG7zgAAERUwq3WLikp0cqVK3XhhReqffv2vuMAABBxCdU5l5SUaMSIESosLFSvXr18xwEAICoSpnMuLi7WihUrdM011+j444/3HQcAgKhJiM65qKhIQ4cOVXFxsbp27eo7DgAAURX3nXNhYaG+/PJL3XHHHTr66KN9xwEAIOriunN2zmnYsGFq2rQphRkAkDLitnPet2+f3nvvPY0dO1b169f3HQcAgJiJ2875/vvvV/fu3SnMAICUE1ZxNrMLzGyZmS03s2Fl3F/PzF4I3v+ZmXWsbqBdu3bpySef1MiRI9WmTZvqPgwAAAmr0uJsZrUlPSLpQkldJfU1s9JTpm+QtM05ly5psqQJ1Q30zDPP6OKLL5aZVfchAABIaOF0zidLWu6cW+mcK5D0vKRLSi1ziaR/BC+/JOlsq2J1LSoq0tixY/WHP/xBLVq0qMqfAgCQVMIpzm0krQ25nhe8rcxlnHNFkrZLalaVILt27dLNN99clT8BACApxXS2tpndJOkmSWrVqpVycnIkSc2bN1daWppyc3NjGSel7Nq16+B4I/IY3+hhbKOL8Y2emoxtOMV5naR2IdfbBm8ra5k8M6sjKU3SltIP5JzLkpQlST179nSZmZmSpMzMTOXk5OjAdUQe4xtdjG/0MLbRxfhGT03GNpzV2vMkdTKzY8zsMElXSZpRapkZkvoHL/9a0vvOOVetRAAApLhKO2fnXJGZ3SLpbUm1JT3lnFtsZndLmu+cmyHpSUnPmNlySVsVKOAAAKAazFeDa2abJH0XclNzSZu9hEkNjG90Mb7Rw9hGF+MbPaXHtoNzLqzdkbwV59LMbL5zrqfvHMmK8Y0uxjd6GNvoYnyjpyZjG7eH7wQAIFVRnAEAiDPxVJyzfAdIcoxvdDG+0cPYRhfjGz3VHtu42eYMAAAC4qlzBgAA8lCcY3n6yVQUxvgONLMlZvaVmf3HzDr4yJmIKhvbkOUuNzNnZsyArYJwxtfMrgx+fhebWXasMyaqML4X2pvZB2b2RfC74Zc+ciYiM3vKzH4ws0Xl3G9m9nBw7L8ysx5hPbBzLmb/FDiIyQpJx0o6TNKXkrqWWuaPkv4evHyVpBdimTGR/4U5vr+QdETw8h8Y38iNbXC5hpJmSZojqafv3InyL8zPbidJX0hqErze0nfuRPgX5thmSfpD8HJXSat9506Uf5LOkNRD0qJy7v+lpDclmaRTJH0WzuPGunOOyeknU1il4+uc+8A5tyd4dY4Cx0pH5cL57ErSPQqcz3xfLMMlgXDG97eSHnHObZMk59wPMc6YqMIZWyepUfBymqT1McyX0JxzsxQ4MmZ5LpE0zQXMkdTYzI6u7HFjXZxjcvrJFBbO+Ia6QYFfdKhcpWMbXF3Vzjn3RiyDJYlwPrudJXU2s9lmNsfMLohZusQWztiOlnSNmeVJminpT7GJlhKq+r0sKcanjET8MLNrJPWUdKbvLMnAzGpJmiTpes9RklkdBVZtZyqwxmeWmZ3onMv3mio59JU01Tn3oJn9XIFzJXRzzpX4DpaqYt05V+X0k6ro9JMoUzjjKzM7R9Jdki52zu2PUbZEV9nYNpTUTVKOma1WYNvSDCaFhS2cz26epBnOuULn3CpJ3yhQrFGxcMb2BknTJck596mk+gocFxo1F9b3cmmxLs6cfjK6Kh1fM+su6TEFCjPb7MJX4dg657Y755o75zo65zoqsD3/YufcfD9xE0443w2vKdA1y8yaK7Cae2UsQyaocMZ2jaSzJcnMjlegOG+KacrkNUPSdcFZ26dI2u6c21DZH8V0tbbj9JNRFeb4TpR0pKQXg/Ps1jjnLvYWOkGEObaopjDH921J55nZEknFkgY751irVokwx/YOSY+b2QAFJoddT1MUHjN7ToEfjc2D2+z/LKmuJDnn/q7ANvxfSlouaY+k34T1uIw/AADxhSOEAQAQZyjOAADEGYozAABxhuIMAECcoTgDABBnKM4AAMQZijMAAHGG4gwAQJz5/9pG7qfCfJlNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y48xbZjOKsUQ"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sb_mHSxKsUQ"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bobdu6p6KsUQ",
        "outputId": "060f26d6-f181-4b9e-9ad8-4fb682433333"
      },
      "source": [
        "run_hist_1.history.keys()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlS583nLKsUQ"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "dukR-KFXKsUR",
        "outputId": "77c481b3-36f9-4b98-d4fd-bc130da6d774"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdbb6058050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ5_q7gEKsUR"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5GppCl7KsUR",
        "outputId": "44b9c8c7-d08c-4190-da63-f9476f437ac9"
      },
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7153 - val_loss: 0.5572 - val_accuracy: 0.7135\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7153 - val_loss: 0.5568 - val_accuracy: 0.7135\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7153 - val_loss: 0.5565 - val_accuracy: 0.7135\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7153 - val_loss: 0.5562 - val_accuracy: 0.7135\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7153 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7170 - val_loss: 0.5555 - val_accuracy: 0.7135\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7205 - val_loss: 0.5552 - val_accuracy: 0.7083\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7222 - val_loss: 0.5548 - val_accuracy: 0.7083\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7205 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7222 - val_loss: 0.5542 - val_accuracy: 0.7031\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7222 - val_loss: 0.5538 - val_accuracy: 0.7083\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7257 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7257 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7274 - val_loss: 0.5528 - val_accuracy: 0.7188\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7274 - val_loss: 0.5525 - val_accuracy: 0.7188\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7292 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7274 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7292 - val_loss: 0.5515 - val_accuracy: 0.7240\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7274 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7274 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7274 - val_loss: 0.5506 - val_accuracy: 0.7240\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7292 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7292 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7309 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7309 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7292 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7309 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7309 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7309 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7309 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7292 - val_loss: 0.5475 - val_accuracy: 0.7396\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7309 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7309 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7326 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7326 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7309 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7326 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7326 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7326 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7326 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7326 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7344 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7326 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7344 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7344 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7344 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7378 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7378 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7396 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7413 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7413 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7431 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7431 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7431 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7483 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7483 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7483 - val_loss: 0.5399 - val_accuracy: 0.7448\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7483 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7500 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7500 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7500 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7500 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7465 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7483 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7448 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7448 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7448 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7483 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7483 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7483 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7483 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7465 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7465 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7465 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7465 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7465 - val_loss: 0.5349 - val_accuracy: 0.7552\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7465 - val_loss: 0.5347 - val_accuracy: 0.7552\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7465 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7465 - val_loss: 0.5339 - val_accuracy: 0.7552\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7465 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7465 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7465 - val_loss: 0.5332 - val_accuracy: 0.7500\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7448 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7448 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7448 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7465 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7448 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7465 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7465 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7465 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7483 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7500 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7517 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7517 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7517 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7500 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7500 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7500 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7500 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7500 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7483 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7500 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7500 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7500 - val_loss: 0.5276 - val_accuracy: 0.7500\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7500 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7500 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7517 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7517 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7535 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7535 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7552 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7535 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7535 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7552 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7552 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7552 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7552 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7552 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7552 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7569 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7569 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7587 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7587 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7587 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7587 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7587 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7587 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7587 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7587 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7587 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7587 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7604 - val_loss: 0.5203 - val_accuracy: 0.7656\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7604 - val_loss: 0.5202 - val_accuracy: 0.7656\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7587 - val_loss: 0.5200 - val_accuracy: 0.7656\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7604 - val_loss: 0.5198 - val_accuracy: 0.7656\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7587 - val_loss: 0.5196 - val_accuracy: 0.7656\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7587 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7604 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7656\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7587 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7569 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7569 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7569 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7569 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7569 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7569 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7569 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7569 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7569 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7569 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7569 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7569 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7569 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7569 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7569 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7569 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7569 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7587 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7569 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7587 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7569 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7569 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7552 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7552 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7552 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7552 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7569 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7552 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7569 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7569 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7569 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7569 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7569 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7587 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7587 - val_loss: 0.5129 - val_accuracy: 0.7812\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7569 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7569 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7587 - val_loss: 0.5124 - val_accuracy: 0.7812\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7587 - val_loss: 0.5123 - val_accuracy: 0.7812\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7587 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7587 - val_loss: 0.5120 - val_accuracy: 0.7865\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7587 - val_loss: 0.5118 - val_accuracy: 0.7865\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7587 - val_loss: 0.5117 - val_accuracy: 0.7865\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7587 - val_loss: 0.5115 - val_accuracy: 0.7865\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7587 - val_loss: 0.5114 - val_accuracy: 0.7865\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7587 - val_loss: 0.5113 - val_accuracy: 0.7865\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7587 - val_loss: 0.5111 - val_accuracy: 0.7865\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7587 - val_loss: 0.5110 - val_accuracy: 0.7865\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7587 - val_loss: 0.5108 - val_accuracy: 0.7865\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7587 - val_loss: 0.5107 - val_accuracy: 0.7865\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7587 - val_loss: 0.5106 - val_accuracy: 0.7865\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7587 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7587 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7587 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7587 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7587 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7587 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7604 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7622 - val_loss: 0.5095 - val_accuracy: 0.7812\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7639 - val_loss: 0.5094 - val_accuracy: 0.7812\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7639 - val_loss: 0.5092 - val_accuracy: 0.7812\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7639 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7639 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7812\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.7812\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7639 - val_loss: 0.5085 - val_accuracy: 0.7812\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7639 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7639 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7639 - val_loss: 0.5081 - val_accuracy: 0.7760\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7639 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7656 - val_loss: 0.5071 - val_accuracy: 0.7760\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5070 - val_accuracy: 0.7760\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7760\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7639 - val_loss: 0.5068 - val_accuracy: 0.7760\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7656 - val_loss: 0.5063 - val_accuracy: 0.7760\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7639 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7656 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7656 - val_loss: 0.5060 - val_accuracy: 0.7760\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7656 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7656 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7674 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7656 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7656 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7656 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7674 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7674 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7674 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7674 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7674 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7674 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7674 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7674 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7674 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7674 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7691 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7691 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7691 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7708 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7726 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7760\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7760\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7743 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7743 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7743 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7743 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7743 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7743 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7743 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7743 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7743 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7743 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7743 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7760 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7760 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7760 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7760 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7760 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7760 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7760 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7760 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7760 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7760 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7760\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7760\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7743 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7760\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7760\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7812\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7812\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7812\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7812\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7812\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7812\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7812\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7812\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7812\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7812\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7812\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7812\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7812\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7812\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7812\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7812\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7812\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7812\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7812\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7865\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7812\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7760\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7760\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7760\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7760\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7760 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7760 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7760 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "cKNaZVdYKsUR",
        "outputId": "5f044e43-c3e3-4ce2-ab19-3f8e56bcb03a"
      },
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdbb6017050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d28ROHB8KsUR"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_1qyx_XKsUS"
      },
      "source": [
        "## Exercise 2\n",
        "For this exercise, do the following in the cells below:\n",
        "- Build a model with two hidden layers, each with 6 nodes\n",
        "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "- Use a learning rate of .003 and train for 1500 epochs\n",
        "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "- Plot the roc curve for the predictions\n",
        "\n",
        "Experiment with different learning rates, numbers of epochs, and network structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9RTE1J_KsUS",
        "outputId": "a0ec7c4c-1885-4d2f-eae0-041d1b3fe2b2"
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
        "model_2.add(Dense(6,  activation=\"relu\"))\n",
        "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.7721 - accuracy: 0.3496 - val_loss: 0.7171 - val_accuracy: 0.4167\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.4310 - val_loss: 0.7067 - val_accuracy: 0.4271\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7215 - accuracy: 0.4850 - val_loss: 0.6974 - val_accuracy: 0.4531\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7096 - accuracy: 0.5124 - val_loss: 0.6890 - val_accuracy: 0.4844\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.5198 - val_loss: 0.6815 - val_accuracy: 0.5156\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.5752 - val_loss: 0.6746 - val_accuracy: 0.5312\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5861 - val_loss: 0.6685 - val_accuracy: 0.5625\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.5828 - val_loss: 0.6629 - val_accuracy: 0.5885\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6501 - val_loss: 0.6578 - val_accuracy: 0.6146\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6225 - val_loss: 0.6531 - val_accuracy: 0.6615\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6483 - val_loss: 0.6487 - val_accuracy: 0.6771\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.6233 - val_loss: 0.6448 - val_accuracy: 0.6823\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.6810 - val_loss: 0.6412 - val_accuracy: 0.6927\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.6163 - val_loss: 0.6379 - val_accuracy: 0.7031\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.7057 - val_loss: 0.6348 - val_accuracy: 0.7083\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.7071 - val_loss: 0.6320 - val_accuracy: 0.7135\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6838 - val_loss: 0.6294 - val_accuracy: 0.7083\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6971 - val_loss: 0.6270 - val_accuracy: 0.7083\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6829 - val_loss: 0.6247 - val_accuracy: 0.7188\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6943 - val_loss: 0.6226 - val_accuracy: 0.7240\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6852 - val_loss: 0.6207 - val_accuracy: 0.7240\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6784 - val_loss: 0.6188 - val_accuracy: 0.7188\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6969 - val_loss: 0.6171 - val_accuracy: 0.7188\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7087 - val_loss: 0.6154 - val_accuracy: 0.7240\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6822 - val_loss: 0.6138 - val_accuracy: 0.7292\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7121 - val_loss: 0.6123 - val_accuracy: 0.7292\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6745 - val_loss: 0.6109 - val_accuracy: 0.7292\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6801 - val_loss: 0.6095 - val_accuracy: 0.7240\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6817 - val_loss: 0.6082 - val_accuracy: 0.7240\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6874 - val_loss: 0.6070 - val_accuracy: 0.7240\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6996 - val_loss: 0.6058 - val_accuracy: 0.7188\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.7089 - val_loss: 0.6046 - val_accuracy: 0.7188\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6663 - val_loss: 0.6034 - val_accuracy: 0.7240\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6971 - val_loss: 0.6023 - val_accuracy: 0.7188\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6908 - val_loss: 0.6012 - val_accuracy: 0.7188\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6745 - val_loss: 0.6002 - val_accuracy: 0.7240\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7037 - val_loss: 0.5991 - val_accuracy: 0.7240\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.7023 - val_loss: 0.5981 - val_accuracy: 0.7240\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6918 - val_loss: 0.5971 - val_accuracy: 0.7188\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6722 - val_loss: 0.5960 - val_accuracy: 0.7188\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7118 - val_loss: 0.5950 - val_accuracy: 0.7188\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6872 - val_loss: 0.5941 - val_accuracy: 0.7188\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.7045 - val_loss: 0.5931 - val_accuracy: 0.7188\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6999 - val_loss: 0.5922 - val_accuracy: 0.7188\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6868 - val_loss: 0.5913 - val_accuracy: 0.7188\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7042 - val_loss: 0.5904 - val_accuracy: 0.7188\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.6987 - val_loss: 0.5895 - val_accuracy: 0.7188\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.6799 - val_loss: 0.5886 - val_accuracy: 0.7188\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6907 - val_loss: 0.5877 - val_accuracy: 0.7188\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6971 - val_loss: 0.5869 - val_accuracy: 0.7188\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7313 - val_loss: 0.5860 - val_accuracy: 0.7188\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7103 - val_loss: 0.5852 - val_accuracy: 0.7188\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6824 - val_loss: 0.5843 - val_accuracy: 0.7188\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6896 - val_loss: 0.5834 - val_accuracy: 0.7188\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.6961 - val_loss: 0.5826 - val_accuracy: 0.7188\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6676 - val_loss: 0.5817 - val_accuracy: 0.7188\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.6973 - val_loss: 0.5809 - val_accuracy: 0.7188\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7072 - val_loss: 0.5800 - val_accuracy: 0.7188\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.6968 - val_loss: 0.5791 - val_accuracy: 0.7240\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.6823 - val_loss: 0.5783 - val_accuracy: 0.7240\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6905 - val_loss: 0.5775 - val_accuracy: 0.7240\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6679 - val_loss: 0.5766 - val_accuracy: 0.7240\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6651 - val_loss: 0.5758 - val_accuracy: 0.7240\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.6984 - val_loss: 0.5749 - val_accuracy: 0.7240\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7023 - val_loss: 0.5740 - val_accuracy: 0.7240\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7018 - val_loss: 0.5732 - val_accuracy: 0.7240\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6766 - val_loss: 0.5723 - val_accuracy: 0.7240\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6671 - val_loss: 0.5715 - val_accuracy: 0.7240\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7153 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.6888 - val_loss: 0.5697 - val_accuracy: 0.7240\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.6960 - val_loss: 0.5689 - val_accuracy: 0.7240\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.6863 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7082 - val_loss: 0.5672 - val_accuracy: 0.7240\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6905 - val_loss: 0.5663 - val_accuracy: 0.7240\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7009 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7150 - val_loss: 0.5647 - val_accuracy: 0.7292\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6875 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7250 - val_loss: 0.5630 - val_accuracy: 0.7292\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7078 - val_loss: 0.5622 - val_accuracy: 0.7292\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.6967 - val_loss: 0.5614 - val_accuracy: 0.7292\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7043 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7127 - val_loss: 0.5597 - val_accuracy: 0.7292\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7275 - val_loss: 0.5589 - val_accuracy: 0.7292\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.6821 - val_loss: 0.5581 - val_accuracy: 0.7292\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7141 - val_loss: 0.5573 - val_accuracy: 0.7292\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7002 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.6979 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.6933 - val_loss: 0.5549 - val_accuracy: 0.7292\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7008 - val_loss: 0.5541 - val_accuracy: 0.7292\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.6977 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.6754 - val_loss: 0.5526 - val_accuracy: 0.7240\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7089 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7353 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7217 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.6918 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7001 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.6961 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7279 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.6999 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7058 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7242 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7209 - val_loss: 0.5448 - val_accuracy: 0.7292\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.6963 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.6957 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7164 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.6969 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7351 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.6948 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7021 - val_loss: 0.5401 - val_accuracy: 0.7240\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.6915 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.6917 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7439 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7329 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.6833 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7277 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7223 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7154 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7070 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7343 - val_loss: 0.5343 - val_accuracy: 0.7292\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7582 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7408 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.6969 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7116 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7358 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7366 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7167 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7352 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7340 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7246 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7252 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7302 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7245 - val_loss: 0.5278 - val_accuracy: 0.7344\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7341 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7332 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7371 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7564 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7328 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7213 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7306 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7121 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7513 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7457 - val_loss: 0.5234 - val_accuracy: 0.7344\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7130 - val_loss: 0.5229 - val_accuracy: 0.7344\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7287 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7273 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7465 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7461 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7568 - val_loss: 0.5209 - val_accuracy: 0.7344\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7184 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7321 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7239 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7737 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7596 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7483 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7350 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7467 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7370 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7412 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7101 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7497 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7428 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7322 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7491 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7400 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7577 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7516 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7250 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7563 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7609 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7659 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7410 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7331 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7510 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7425 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7516 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7572 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7253 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7302 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7630 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7682 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7601 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7709 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7424 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7651 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7514 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7549 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7426 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7431 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7586 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7730 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7686 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7549 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7254 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7784 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7620 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7562 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7555 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7326 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7878 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7742 - val_loss: 0.5068 - val_accuracy: 0.7760\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7498 - val_loss: 0.5067 - val_accuracy: 0.7760\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7530 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7837 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7513 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7848 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7837 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7654 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7357 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7796 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7510 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7409 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7714 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7614 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7772 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7771 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7555 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7826 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7638 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7588 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7482 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7524 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7639 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7758 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7631 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7757 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7728 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7848 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7591 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7689 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7404 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7690 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7491 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7683 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7602 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7675 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7509 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7774 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7333 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7681 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7700 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7759 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7687 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7666 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7831 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7737 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7772 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7591 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7669 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7926 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7753 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7519 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7624 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7628 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7599 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7672 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7748 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7816 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7539 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7577 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7750 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7888 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7921 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7622 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7673 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7666 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7832 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7770 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7564 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8097 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7659 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7621 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7750 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8023 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7974 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7707 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7903 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7555 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7381 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7920 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7484 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7482 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7820 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7916 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7626 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7781 - val_loss: 0.5007 - val_accuracy: 0.7760\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7823 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7811 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7716 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7621 - val_loss: 0.5005 - val_accuracy: 0.7760\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7747 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7714 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7729 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7562 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7828 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7826 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7573 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7516 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7826 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7808 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7510 - val_loss: 0.5000 - val_accuracy: 0.7760\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7963 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7838 - val_loss: 0.4999 - val_accuracy: 0.7760\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7798 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7699 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7744 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7696 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7866 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7727 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7892 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7673 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8077 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7737 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7846 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7651 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7683 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7698 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7785 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7645 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7423 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7767 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7756 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7605 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7707 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7618 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7890 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7810 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7793 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8056 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7822 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7811 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8017 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7684 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7940 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7878 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7912 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7977 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7995 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7814 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7858 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7695 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7541 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7823 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7746 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8112 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7933 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7633 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7840 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7943 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7889 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7702 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8050 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7745 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7950 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7861 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7897 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7477 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7820 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7788 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7533 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7880 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8048 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8040 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7841 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7757 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7709 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7974 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7961 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8124 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8020 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7604 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7689 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7935 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8096 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8169 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8113 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7940 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7834 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7689 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8033 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7759 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7822 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8078 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7989 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8099 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7948 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7916 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7825 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7933 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7762 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7972 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8093 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8054 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7878 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7971 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7889 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7799 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7800 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8074 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7929 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8007 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7906 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8034 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7386 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7740 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8181 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.8064 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7757 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.8042 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8137 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7800 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7780 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7890 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8000 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8156 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7789 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7943 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8062 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7785 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8167 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8030 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7766 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7910 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7843 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8176 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8059 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7971 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7986 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8052 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7904 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7809 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7949 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.8162 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7872 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.8051 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8051 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7883 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8130 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7770 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7884 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7735 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7893 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8066 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7818 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7832 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.8065 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7707 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.8085 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7823 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7727 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7890 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7890 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8141 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7951 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7946 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7822 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8251 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7785 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7819 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7907 - val_loss: 0.4947 - val_accuracy: 0.7604\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8139 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7879 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7876 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7897 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7811 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7843 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7884 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8015 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8081 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.8169 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8120 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7995 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7908 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7910 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8081 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7848 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8019 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7902 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8039 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7932 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8094 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8153 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8096 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8053 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7713 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8102 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8174 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7936 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7857 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8111 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7923 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8054 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7970 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8233 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8155 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8065 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7999 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7997 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7989 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8010 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7915 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7925 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.8084 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7961 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7861 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7894 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8038 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8071 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7962 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7984 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8196 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8329 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7926 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7965 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8020 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8111 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7983 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7948 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8049 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8119 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8006 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8027 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8059 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7962 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7846 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.8111 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8192 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.8055 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8213 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7908 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8045 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8094 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7941 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7835 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8135 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8029 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8023 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8147 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8260 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8035 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8018 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7780 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8103 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8150 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7953 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7985 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7839 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7487 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7836 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8148 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.8011 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7858 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7653 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8282 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8000 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7868 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.8087 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.8167 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8032 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7833 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7999 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7881 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7983 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7684 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7747 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7976 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7962 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7958 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8111 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7802 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7991 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7811 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7982 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7889 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8160 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8105 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7984 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8109 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7825 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7665 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7777 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7974 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7978 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8332 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7967 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7868 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8097 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8167 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8037 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8055 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7817 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7737 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7797 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7931 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7867 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8116 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7770 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7567 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7858 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7823 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7932 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7934 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8166 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7856 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7696 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7946 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8177 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8052 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7989 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7945 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8225 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8004 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8076 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8259 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7759 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7771 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7958 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7697 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8161 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7767 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7856 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8161 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7878 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.8018 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8303 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7975 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7883 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8091 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7884 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8006 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7927 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8009 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7945 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7761 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8048 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7898 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8069 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8286 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7798 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7991 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8134 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7821 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8019 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8213 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7874 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7834 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7979 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7907 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7861 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7956 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8222 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8318 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7869 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8026 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7956 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8089 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7965 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7862 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8269 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8088 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8015 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8099 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7716 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8093 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8177 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8070 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7945 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7896 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8119 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8140 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8039 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8212 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8153 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8005 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8201 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7885 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7870 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7967 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8326 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7948 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8191 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7810 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8232 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8162 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8009 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7921 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8062 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8248 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7920 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7813 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8053 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8205 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7892 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.8122 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8097 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8059 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7883 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8243 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7957 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7914 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8028 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7911 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8192 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8150 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8224 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7843 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7981 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8139 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8252 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7943 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8051 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8161 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7954 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7722 - val_loss: 0.4871 - val_accuracy: 0.7865\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8189 - val_loss: 0.4871 - val_accuracy: 0.7865\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7956 - val_loss: 0.4871 - val_accuracy: 0.7865\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7865\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7853 - val_loss: 0.4870 - val_accuracy: 0.7865\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7977 - val_loss: 0.4870 - val_accuracy: 0.7865\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7817 - val_loss: 0.4869 - val_accuracy: 0.7865\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7859 - val_loss: 0.4869 - val_accuracy: 0.7865\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8201 - val_loss: 0.4869 - val_accuracy: 0.7865\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8012 - val_loss: 0.4869 - val_accuracy: 0.7865\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7885 - val_loss: 0.4868 - val_accuracy: 0.7865\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8330 - val_loss: 0.4868 - val_accuracy: 0.7865\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7877 - val_loss: 0.4868 - val_accuracy: 0.7865\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7865\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7968 - val_loss: 0.4867 - val_accuracy: 0.7865\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7840 - val_loss: 0.4867 - val_accuracy: 0.7865\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7945 - val_loss: 0.4866 - val_accuracy: 0.7865\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.4866 - val_accuracy: 0.7865\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7845 - val_loss: 0.4866 - val_accuracy: 0.7865\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7968 - val_loss: 0.4865 - val_accuracy: 0.7865\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8348 - val_loss: 0.4865 - val_accuracy: 0.7865\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8172 - val_loss: 0.4865 - val_accuracy: 0.7865\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7710 - val_loss: 0.4864 - val_accuracy: 0.7812\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7993 - val_loss: 0.4864 - val_accuracy: 0.7812\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7996 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8096 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7971 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7901 - val_loss: 0.4862 - val_accuracy: 0.7812\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8055 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7762 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8083 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8191 - val_loss: 0.4860 - val_accuracy: 0.7812\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7990 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.4859 - val_accuracy: 0.7812\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7997 - val_loss: 0.4858 - val_accuracy: 0.7812\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8026 - val_loss: 0.4858 - val_accuracy: 0.7812\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7833 - val_loss: 0.4857 - val_accuracy: 0.7812\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8043 - val_loss: 0.4857 - val_accuracy: 0.7812\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7845 - val_loss: 0.4857 - val_accuracy: 0.7812\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8035 - val_loss: 0.4857 - val_accuracy: 0.7812\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7946 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8027 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8211 - val_loss: 0.4856 - val_accuracy: 0.7812\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8146 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8132 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8023 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8255 - val_loss: 0.4855 - val_accuracy: 0.7812\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7913 - val_loss: 0.4854 - val_accuracy: 0.7812\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7927 - val_loss: 0.4854 - val_accuracy: 0.7812\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8174 - val_loss: 0.4854 - val_accuracy: 0.7812\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8183 - val_loss: 0.4853 - val_accuracy: 0.7812\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7914 - val_loss: 0.4853 - val_accuracy: 0.7812\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8174 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7862 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8210 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8071 - val_loss: 0.4852 - val_accuracy: 0.7812\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7720 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7816 - val_loss: 0.4851 - val_accuracy: 0.7812\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8280 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8071 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8264 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8076 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8092 - val_loss: 0.4850 - val_accuracy: 0.7812\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7946 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8306 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8058 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7961 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8023 - val_loss: 0.4849 - val_accuracy: 0.7812\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8174 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8173 - val_loss: 0.4848 - val_accuracy: 0.7812\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8222 - val_loss: 0.4848 - val_accuracy: 0.7865\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7764 - val_loss: 0.4848 - val_accuracy: 0.7865\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.8025 - val_loss: 0.4847 - val_accuracy: 0.7917\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7868 - val_loss: 0.4847 - val_accuracy: 0.7865\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8327 - val_loss: 0.4847 - val_accuracy: 0.7865\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8263 - val_loss: 0.4847 - val_accuracy: 0.7865\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8029 - val_loss: 0.4846 - val_accuracy: 0.7865\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8368 - val_loss: 0.4847 - val_accuracy: 0.7865\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7905 - val_loss: 0.4846 - val_accuracy: 0.7865\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8105 - val_loss: 0.4846 - val_accuracy: 0.7865\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7876 - val_loss: 0.4846 - val_accuracy: 0.7865\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8082 - val_loss: 0.4845 - val_accuracy: 0.7865\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8023 - val_loss: 0.4845 - val_accuracy: 0.7865\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8109 - val_loss: 0.4845 - val_accuracy: 0.7865\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.4845 - val_accuracy: 0.7865\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8057 - val_loss: 0.4844 - val_accuracy: 0.7865\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8128 - val_loss: 0.4844 - val_accuracy: 0.7865\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.8145 - val_loss: 0.4844 - val_accuracy: 0.7865\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8000 - val_loss: 0.4844 - val_accuracy: 0.7865\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7976 - val_loss: 0.4844 - val_accuracy: 0.7865\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8217 - val_loss: 0.4843 - val_accuracy: 0.7865\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7974 - val_loss: 0.4843 - val_accuracy: 0.7865\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7910 - val_loss: 0.4843 - val_accuracy: 0.7865\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8100 - val_loss: 0.4843 - val_accuracy: 0.7865\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7862 - val_loss: 0.4842 - val_accuracy: 0.7865\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8175 - val_loss: 0.4842 - val_accuracy: 0.7865\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7978 - val_loss: 0.4842 - val_accuracy: 0.7865\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8020 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8032 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7938 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8306 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8096 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8222 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7894 - val_loss: 0.4840 - val_accuracy: 0.7865\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8163 - val_loss: 0.4840 - val_accuracy: 0.7865\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8011 - val_loss: 0.4840 - val_accuracy: 0.7865\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8084 - val_loss: 0.4840 - val_accuracy: 0.7865\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8047 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8207 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7992 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8005 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7878 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7960 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7801 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7897 - val_loss: 0.4839 - val_accuracy: 0.7865\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8075 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8181 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8119 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7962 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8142 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7972 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8005 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8027 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7969 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8027 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8116 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7943 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8040 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8069 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7926 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7974 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8103 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8375 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8226 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7955 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.8109 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8141 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8004 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8111 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7664 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8107 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8240 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8168 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8279 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8057 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.8265 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7977 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.8005 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8320 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8211 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8106 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8148 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7914 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8066 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8005 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.8003 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7968 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8225 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8234 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8242 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7993 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8205 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8012 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8023 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8163 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8215 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8005 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8275 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8210 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8200 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8192 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8146 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7670 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8030 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8229 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8321 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8167 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8144 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8129 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8036 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8107 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8155 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8280 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7994 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8155 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7704 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8050 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8228 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8084 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8172 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8117 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8170 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8082 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8259 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8088 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8201 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8282 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8125 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7983 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8271 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7856 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8138 - val_loss: 0.4826 - val_accuracy: 0.7917\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8367 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8132 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8023 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8153 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7893 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8227 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8283 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8126 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8125 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8179 - val_loss: 0.4825 - val_accuracy: 0.7917\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8013 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8014 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8122 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8058 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8053 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.8048 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8198 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8373 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8434 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8083 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8109 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7901 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8059 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7928 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8036 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8017 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7941 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7963 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7857 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8305 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8147 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8094 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7982 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.8125 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7955 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8308 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8047 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8194 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8123 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8283 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8112 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8233 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8239 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8139 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8077 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8081 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8126 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8235 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7728 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8219 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8127 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8253 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.8075 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7944 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8060 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8115 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8092 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8049 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8005 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8071 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.7977 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8210 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8016 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8042 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8101 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8219 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8034 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8332 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8152 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8239 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8126 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8116 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8328 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8061 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7993 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8287 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8100 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8160 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8324 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8145 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8194 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8095 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7977 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8041 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8019 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8266 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7985 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7957 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8254 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7885 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8160 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8166 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8153 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8042 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8050 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8039 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7969 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7935 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8254 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8003 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8064 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8213 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8234 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7916 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8042 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8096 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8057 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7938 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8302 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8042 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.8012 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8198 - val_loss: 0.4837 - val_accuracy: 0.7917\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7941 - val_loss: 0.4837 - val_accuracy: 0.7917\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8341 - val_loss: 0.4837 - val_accuracy: 0.7917\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7917\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7772 - val_loss: 0.4838 - val_accuracy: 0.7917\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7992 - val_loss: 0.4838 - val_accuracy: 0.7917\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8040 - val_loss: 0.4839 - val_accuracy: 0.7917\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8191 - val_loss: 0.4839 - val_accuracy: 0.7917\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8223 - val_loss: 0.4839 - val_accuracy: 0.7917\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8223 - val_loss: 0.4839 - val_accuracy: 0.7917\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7978 - val_loss: 0.4839 - val_accuracy: 0.7917\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8249 - val_loss: 0.4839 - val_accuracy: 0.7917\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8130 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8183 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8040 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8037 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8266 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8265 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7958 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8256 - val_loss: 0.4840 - val_accuracy: 0.7917\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7838 - val_loss: 0.4841 - val_accuracy: 0.7917\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7957 - val_loss: 0.4841 - val_accuracy: 0.7969\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8075 - val_loss: 0.4841 - val_accuracy: 0.7969\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8078 - val_loss: 0.4841 - val_accuracy: 0.7969\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8070 - val_loss: 0.4841 - val_accuracy: 0.7969\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8041 - val_loss: 0.4841 - val_accuracy: 0.7969\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8134 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8261 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8138 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7834 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7989 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8096 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7987 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8035 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8196 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8242 - val_loss: 0.4842 - val_accuracy: 0.7969\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7661 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8192 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7984 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8091 - val_loss: 0.4843 - val_accuracy: 0.7969\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8056 - val_loss: 0.4844 - val_accuracy: 0.7969\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8058 - val_loss: 0.4844 - val_accuracy: 0.7969\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.4845 - val_accuracy: 0.7969\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7947 - val_loss: 0.4845 - val_accuracy: 0.7969\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7719 - val_loss: 0.4845 - val_accuracy: 0.7969\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8031 - val_loss: 0.4845 - val_accuracy: 0.7969\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7912 - val_loss: 0.4846 - val_accuracy: 0.7969\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7980 - val_loss: 0.4846 - val_accuracy: 0.7969\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8133 - val_loss: 0.4846 - val_accuracy: 0.7969\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8052 - val_loss: 0.4846 - val_accuracy: 0.7969\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7929 - val_loss: 0.4847 - val_accuracy: 0.7969\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7930 - val_loss: 0.4847 - val_accuracy: 0.7969\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.7966 - val_loss: 0.4847 - val_accuracy: 0.7969\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8341 - val_loss: 0.4847 - val_accuracy: 0.7969\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8136 - val_loss: 0.4847 - val_accuracy: 0.7969\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8087 - val_loss: 0.4847 - val_accuracy: 0.7969\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8033 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8131 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8037 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8092 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8182 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7975 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8002 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8362 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7790 - val_loss: 0.4848 - val_accuracy: 0.7969\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8041 - val_loss: 0.4849 - val_accuracy: 0.7969\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7928 - val_loss: 0.4849 - val_accuracy: 0.7969\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8156 - val_loss: 0.4849 - val_accuracy: 0.7969\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8176 - val_loss: 0.4849 - val_accuracy: 0.7969\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8177 - val_loss: 0.4849 - val_accuracy: 0.7969\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8077 - val_loss: 0.4849 - val_accuracy: 0.7969\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7992 - val_loss: 0.4850 - val_accuracy: 0.7969\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7999 - val_loss: 0.4850 - val_accuracy: 0.7969\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7905 - val_loss: 0.4850 - val_accuracy: 0.7969\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8005 - val_loss: 0.4850 - val_accuracy: 0.7969\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8079 - val_loss: 0.4851 - val_accuracy: 0.7969\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8251 - val_loss: 0.4851 - val_accuracy: 0.7969\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8039 - val_loss: 0.4851 - val_accuracy: 0.7969\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8084 - val_loss: 0.4851 - val_accuracy: 0.7969\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8105 - val_loss: 0.4851 - val_accuracy: 0.7969\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8195 - val_loss: 0.4852 - val_accuracy: 0.7969\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8133 - val_loss: 0.4852 - val_accuracy: 0.7969\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8129 - val_loss: 0.4852 - val_accuracy: 0.7969\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8013 - val_loss: 0.4852 - val_accuracy: 0.7969\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8095 - val_loss: 0.4853 - val_accuracy: 0.7969\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8090 - val_loss: 0.4853 - val_accuracy: 0.7969\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8307 - val_loss: 0.4853 - val_accuracy: 0.7969\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.7938 - val_loss: 0.4853 - val_accuracy: 0.7969\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8263 - val_loss: 0.4854 - val_accuracy: 0.7917\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8196 - val_loss: 0.4854 - val_accuracy: 0.7917\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7870 - val_loss: 0.4854 - val_accuracy: 0.7917\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8027 - val_loss: 0.4854 - val_accuracy: 0.7917\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8037 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8337 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8154 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7948 - val_loss: 0.4855 - val_accuracy: 0.7917\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8154 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8088 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8125 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7850 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8134 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8202 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8104 - val_loss: 0.4856 - val_accuracy: 0.7917\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8100 - val_loss: 0.4857 - val_accuracy: 0.7917\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8046 - val_loss: 0.4857 - val_accuracy: 0.7917\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7873 - val_loss: 0.4857 - val_accuracy: 0.7917\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8214 - val_loss: 0.4857 - val_accuracy: 0.7865\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8205 - val_loss: 0.4858 - val_accuracy: 0.7865\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8150 - val_loss: 0.4858 - val_accuracy: 0.7865\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7923 - val_loss: 0.4858 - val_accuracy: 0.7865\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8140 - val_loss: 0.4858 - val_accuracy: 0.7865\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7771 - val_loss: 0.4859 - val_accuracy: 0.7865\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7807 - val_loss: 0.4859 - val_accuracy: 0.7865\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8354 - val_loss: 0.4859 - val_accuracy: 0.7865\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7956 - val_loss: 0.4859 - val_accuracy: 0.7865\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8088 - val_loss: 0.4860 - val_accuracy: 0.7865\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8271 - val_loss: 0.4860 - val_accuracy: 0.7865\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7841 - val_loss: 0.4860 - val_accuracy: 0.7865\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8109 - val_loss: 0.4860 - val_accuracy: 0.7865\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7819 - val_loss: 0.4861 - val_accuracy: 0.7865\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8191 - val_loss: 0.4861 - val_accuracy: 0.7865\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7858 - val_loss: 0.4861 - val_accuracy: 0.7865\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8362 - val_loss: 0.4861 - val_accuracy: 0.7865\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8014 - val_loss: 0.4861 - val_accuracy: 0.7865\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8141 - val_loss: 0.4862 - val_accuracy: 0.7865\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7866 - val_loss: 0.4862 - val_accuracy: 0.7865\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8171 - val_loss: 0.4862 - val_accuracy: 0.7865\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7946 - val_loss: 0.4863 - val_accuracy: 0.7865\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8033 - val_loss: 0.4863 - val_accuracy: 0.7917\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7962 - val_loss: 0.4863 - val_accuracy: 0.7917\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8155 - val_loss: 0.4863 - val_accuracy: 0.7917\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7976 - val_loss: 0.4864 - val_accuracy: 0.7917\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8249 - val_loss: 0.4864 - val_accuracy: 0.7917\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7942 - val_loss: 0.4864 - val_accuracy: 0.7917\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7873 - val_loss: 0.4865 - val_accuracy: 0.7917\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8168 - val_loss: 0.4865 - val_accuracy: 0.7917\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7849 - val_loss: 0.4865 - val_accuracy: 0.7917\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8243 - val_loss: 0.4866 - val_accuracy: 0.7917\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8231 - val_loss: 0.4866 - val_accuracy: 0.7917\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8106 - val_loss: 0.4866 - val_accuracy: 0.7917\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8016 - val_loss: 0.4867 - val_accuracy: 0.7917\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7989 - val_loss: 0.4867 - val_accuracy: 0.7917\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8262 - val_loss: 0.4867 - val_accuracy: 0.7917\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7928 - val_loss: 0.4868 - val_accuracy: 0.7917\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8113 - val_loss: 0.4868 - val_accuracy: 0.7917\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8021 - val_loss: 0.4868 - val_accuracy: 0.7917\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8015 - val_loss: 0.4868 - val_accuracy: 0.7917\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8215 - val_loss: 0.4869 - val_accuracy: 0.7917\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8240 - val_loss: 0.4869 - val_accuracy: 0.7917\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7868 - val_loss: 0.4869 - val_accuracy: 0.7917\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7963 - val_loss: 0.4870 - val_accuracy: 0.7917\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8228 - val_loss: 0.4870 - val_accuracy: 0.7917\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8106 - val_loss: 0.4870 - val_accuracy: 0.7917\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7829 - val_loss: 0.4870 - val_accuracy: 0.7917\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8081 - val_loss: 0.4870 - val_accuracy: 0.7917\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8100 - val_loss: 0.4871 - val_accuracy: 0.7917\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8145 - val_loss: 0.4871 - val_accuracy: 0.7917\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7810 - val_loss: 0.4871 - val_accuracy: 0.7917\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8298 - val_loss: 0.4871 - val_accuracy: 0.7917\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8144 - val_loss: 0.4872 - val_accuracy: 0.7917\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8164 - val_loss: 0.4872 - val_accuracy: 0.7917\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8062 - val_loss: 0.4872 - val_accuracy: 0.7917\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8151 - val_loss: 0.4872 - val_accuracy: 0.7917\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7996 - val_loss: 0.4873 - val_accuracy: 0.7917\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.8039 - val_loss: 0.4873 - val_accuracy: 0.7917\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8122 - val_loss: 0.4873 - val_accuracy: 0.7917\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8085 - val_loss: 0.4874 - val_accuracy: 0.7917\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8370 - val_loss: 0.4874 - val_accuracy: 0.7917\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8374 - val_loss: 0.4874 - val_accuracy: 0.7917\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8041 - val_loss: 0.4874 - val_accuracy: 0.7917\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8089 - val_loss: 0.4875 - val_accuracy: 0.7917\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8174 - val_loss: 0.4875 - val_accuracy: 0.7917\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8161 - val_loss: 0.4876 - val_accuracy: 0.7917\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8087 - val_loss: 0.4875 - val_accuracy: 0.7917\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8100 - val_loss: 0.4876 - val_accuracy: 0.7917\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8052 - val_loss: 0.4876 - val_accuracy: 0.7917\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8057 - val_loss: 0.4876 - val_accuracy: 0.7917\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.4877 - val_accuracy: 0.7865\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7895 - val_loss: 0.4877 - val_accuracy: 0.7917\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8340 - val_loss: 0.4877 - val_accuracy: 0.7917\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8065 - val_loss: 0.4877 - val_accuracy: 0.7865\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8037 - val_loss: 0.4878 - val_accuracy: 0.7865\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8079 - val_loss: 0.4878 - val_accuracy: 0.7865\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8068 - val_loss: 0.4878 - val_accuracy: 0.7865\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8086 - val_loss: 0.4879 - val_accuracy: 0.7865\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8324 - val_loss: 0.4879 - val_accuracy: 0.7865\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8001 - val_loss: 0.4879 - val_accuracy: 0.7865\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7903 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8233 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8310 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8414 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8067 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8248 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8063 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8113 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8252 - val_loss: 0.4882 - val_accuracy: 0.7917\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7750 - val_loss: 0.4882 - val_accuracy: 0.7917\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8229 - val_loss: 0.4882 - val_accuracy: 0.7917\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8053 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8360 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7966 - val_loss: 0.4883 - val_accuracy: 0.7917\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7935 - val_loss: 0.4884 - val_accuracy: 0.7917\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8248 - val_loss: 0.4884 - val_accuracy: 0.7917\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7851 - val_loss: 0.4884 - val_accuracy: 0.7917\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8300 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8346 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8201 - val_loss: 0.4885 - val_accuracy: 0.7917\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8111 - val_loss: 0.4886 - val_accuracy: 0.7917\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8153 - val_loss: 0.4886 - val_accuracy: 0.7917\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8272 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7953 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8313 - val_loss: 0.4887 - val_accuracy: 0.7917\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8204 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8023 - val_loss: 0.4888 - val_accuracy: 0.7917\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8104 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7937 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.8020 - val_loss: 0.4889 - val_accuracy: 0.7917\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7971 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7957 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8125 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8112 - val_loss: 0.4890 - val_accuracy: 0.7917\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8331 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8190 - val_loss: 0.4891 - val_accuracy: 0.7917\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8271 - val_loss: 0.4892 - val_accuracy: 0.7917\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8155 - val_loss: 0.4892 - val_accuracy: 0.7917\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.8006 - val_loss: 0.4892 - val_accuracy: 0.7917\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8251 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.8141 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8164 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8089 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8071 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8114 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8090 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8082 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8166 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8001 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8023 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7922 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7825 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8156 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8136 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7858 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8177 - val_loss: 0.4898 - val_accuracy: 0.7969\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7846 - val_loss: 0.4898 - val_accuracy: 0.7969\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7906 - val_loss: 0.4898 - val_accuracy: 0.7969\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8331 - val_loss: 0.4899 - val_accuracy: 0.7917\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4899 - val_accuracy: 0.7917\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8210 - val_loss: 0.4899 - val_accuracy: 0.7917\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8260 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8241 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8157 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7939 - val_loss: 0.4900 - val_accuracy: 0.7969\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8180 - val_loss: 0.4901 - val_accuracy: 0.7969\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8050 - val_loss: 0.4901 - val_accuracy: 0.7969\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7977 - val_loss: 0.4901 - val_accuracy: 0.7969\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8306 - val_loss: 0.4902 - val_accuracy: 0.7969\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8113 - val_loss: 0.4902 - val_accuracy: 0.7969\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7925 - val_loss: 0.4902 - val_accuracy: 0.7969\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8143 - val_loss: 0.4902 - val_accuracy: 0.7969\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8297 - val_loss: 0.4902 - val_accuracy: 0.7969\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8305 - val_loss: 0.4902 - val_accuracy: 0.7969\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7992 - val_loss: 0.4903 - val_accuracy: 0.7969\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8153 - val_loss: 0.4903 - val_accuracy: 0.7969\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8169 - val_loss: 0.4903 - val_accuracy: 0.7969\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8032 - val_loss: 0.4903 - val_accuracy: 0.7969\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8293 - val_loss: 0.4903 - val_accuracy: 0.7969\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8078 - val_loss: 0.4903 - val_accuracy: 0.7969\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8301 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8135 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8304 - val_loss: 0.4905 - val_accuracy: 0.7917\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8053 - val_loss: 0.4905 - val_accuracy: 0.7917\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8244 - val_loss: 0.4905 - val_accuracy: 0.7917\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8269 - val_loss: 0.4905 - val_accuracy: 0.7917\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8002 - val_loss: 0.4905 - val_accuracy: 0.7917\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8099 - val_loss: 0.4906 - val_accuracy: 0.7917\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8161 - val_loss: 0.4906 - val_accuracy: 0.7917\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8154 - val_loss: 0.4906 - val_accuracy: 0.7917\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8093 - val_loss: 0.4906 - val_accuracy: 0.7917\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7884 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8294 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8138 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8030 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7984 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7794 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8293 - val_loss: 0.4907 - val_accuracy: 0.7917\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7871 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8127 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8012 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8065 - val_loss: 0.4909 - val_accuracy: 0.7917\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8072 - val_loss: 0.4909 - val_accuracy: 0.7917\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7853 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7932 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8214 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7974 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7912 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7982 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8476 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7821 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8054 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8245 - val_loss: 0.4911 - val_accuracy: 0.7917\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8234 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8205 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8194 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.8407 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8194 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8004 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8264 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8013 - val_loss: 0.4912 - val_accuracy: 0.7917\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7932 - val_loss: 0.4913 - val_accuracy: 0.7917\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7954 - val_loss: 0.4913 - val_accuracy: 0.7917\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7875 - val_loss: 0.4913 - val_accuracy: 0.7917\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8201 - val_loss: 0.4914 - val_accuracy: 0.7917\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8187 - val_loss: 0.4914 - val_accuracy: 0.7917\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8335 - val_loss: 0.4914 - val_accuracy: 0.7865\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8454 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7883 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8177 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8106 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8103 - val_loss: 0.4915 - val_accuracy: 0.7865\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7923 - val_loss: 0.4916 - val_accuracy: 0.7865\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8230 - val_loss: 0.4916 - val_accuracy: 0.7865\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8059 - val_loss: 0.4916 - val_accuracy: 0.7865\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7853 - val_loss: 0.4916 - val_accuracy: 0.7865\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8315 - val_loss: 0.4917 - val_accuracy: 0.7865\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7912 - val_loss: 0.4917 - val_accuracy: 0.7865\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8185 - val_loss: 0.4917 - val_accuracy: 0.7865\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8151 - val_loss: 0.4917 - val_accuracy: 0.7865\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8151 - val_loss: 0.4917 - val_accuracy: 0.7865\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8006 - val_loss: 0.4917 - val_accuracy: 0.7865\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8298 - val_loss: 0.4918 - val_accuracy: 0.7865\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8019 - val_loss: 0.4918 - val_accuracy: 0.7865\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8208 - val_loss: 0.4918 - val_accuracy: 0.7865\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8131 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8122 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8239 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8265 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8097 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8363 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8030 - val_loss: 0.4920 - val_accuracy: 0.7865\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8083 - val_loss: 0.4920 - val_accuracy: 0.7865\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8240 - val_loss: 0.4920 - val_accuracy: 0.7865\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7920 - val_loss: 0.4920 - val_accuracy: 0.7865\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8166 - val_loss: 0.4920 - val_accuracy: 0.7865\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8205 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8061 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8128 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8284 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8106 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8262 - val_loss: 0.4922 - val_accuracy: 0.7865\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7672 - val_loss: 0.4922 - val_accuracy: 0.7865\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8184 - val_loss: 0.4922 - val_accuracy: 0.7865\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8297 - val_loss: 0.4922 - val_accuracy: 0.7865\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8099 - val_loss: 0.4922 - val_accuracy: 0.7812\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8122 - val_loss: 0.4923 - val_accuracy: 0.7865\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.7984 - val_loss: 0.4923 - val_accuracy: 0.7865\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8278 - val_loss: 0.4923 - val_accuracy: 0.7812\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8199 - val_loss: 0.4923 - val_accuracy: 0.7865\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8002 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8110 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.7989 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8213 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7994 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8283 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8464 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8341 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8358 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7961 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8177 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8125 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8278 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8234 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8176 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8119 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8152 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8215 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8067 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8011 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8180 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8032 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8182 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8128 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7975 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7907 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8333 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8029 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8173 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8071 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8153 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8072 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7732 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7965 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8246 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8176 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8153 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7991 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7769 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7888 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8048 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.7961 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8231 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7957 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7877 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8041 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7822 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8490 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8096 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7987 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8191 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8007 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8039 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8218 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8210 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8190 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8321 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8202 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8394 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8209 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8363 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8376 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7897 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8027 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8187 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8268 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8040 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8128 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8221 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8155 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8321 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8029 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8130 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8039 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7789 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8052 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8128 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7975 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8265 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7973 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7950 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8339 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7888 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7886 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8031 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7911 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7944 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7928 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8092 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8170 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8085 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7964 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8187 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8162 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8236 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8079 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8157 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8360 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7998 - val_loss: 0.4942 - val_accuracy: 0.7760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jZedj0PKsUS",
        "outputId": "4b0e5dda-4c72-4c91-e188-0642fbc3742b"
      },
      "source": [
        "run_hist_2.history.keys()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "f0twOleMKsUT",
        "outputId": "01d2a2ad-0cfd-4525-f4e5-6b0ccbe1eabb"
      },
      "source": [
        "n = len(run_hist_2.history[\"loss\"])\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "ax.set_title('Loss over iterations')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_title('Accuracy over iterations')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy over iterations')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "rQaZJtAlKsUT",
        "outputId": "aae6caa0-aad3-476b-ccd2-c83cff049744"
      },
      "source": [
        "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
        "print('')\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
        "### END SOLUTION"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy is 0.776\n",
            "roc-auc is 0.829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFmyX1J6PGC9"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}